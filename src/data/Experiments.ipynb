{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36rmtwuuP9xw",
        "outputId": "547ffebc-56aa-4758-918a-952bc66df79c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IJ7StLrRPzq",
        "outputId": "22af6094-4011-41d9-c02d-4b61a781241c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/PRIM\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/PRIM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHKH_ghbRcye",
        "outputId": "116032a3-c336-49d1-9287-f0202e9ef066"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'PRIM'...\n",
            "remote: Enumerating objects: 20, done.\u001b[K\n",
            "remote: Counting objects: 100% (20/20), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 20 (delta 1), reused 20 (delta 1), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (20/20), 7.79 KiB | 7.79 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://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@github.com/yesminete/PRIM.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QAm9IS8Riog",
        "outputId": "66b572ea-8cd1-4287-b3fd-7e4d654cfb47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/PRIM/code/src/data\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/PRIM/code/src/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJ5xWg0rVDKp"
      },
      "outputs": [],
      "source": [
        "import preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ew7adJfgVLHZ",
        "outputId": "09b89871-c7b2-46f3-ef18-f2f54bbee869"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Interpolated DataFrame:\n",
            "   frame  player1_nose_x  player1_nose_y  player1_L_shoulder_x  \\\n",
            "0      0             0.0             0.0                   0.0   \n",
            "1      1             0.0             0.0                   0.0   \n",
            "2      2             0.0             0.0                   0.0   \n",
            "3      3             0.0             0.0                   0.0   \n",
            "4      4             0.0             0.0                   0.0   \n",
            "\n",
            "   player1_L_shoulder_y  player1_R_shoulder_x  player1_R_shoulder_y  \\\n",
            "0                   0.0                   0.0                   0.0   \n",
            "1                   0.0                   0.0                   0.0   \n",
            "2                   0.0                   0.0                   0.0   \n",
            "3                   0.0                   0.0                   0.0   \n",
            "4                   0.0                   0.0                   0.0   \n",
            "\n",
            "   player1_L_elbow_x  player1_L_elbow_y  player1_R_elbow_x  ...  \\\n",
            "0                0.0                0.0                0.0  ...   \n",
            "1                0.0                0.0                0.0  ...   \n",
            "2                0.0                0.0                0.0  ...   \n",
            "3                0.0                0.0                0.0  ...   \n",
            "4                0.0                0.0                0.0  ...   \n",
            "\n",
            "   player2_L_knee_x_flag  player2_L_knee_y_flag  player2_R_knee_x_flag  \\\n",
            "0                      1                      1                      1   \n",
            "1                      1                      1                      1   \n",
            "2                      1                      1                      1   \n",
            "3                      1                      1                      1   \n",
            "4                      1                      1                      1   \n",
            "\n",
            "   player2_R_knee_y_flag  player2_L_ankle_x_flag  player2_L_ankle_y_flag  \\\n",
            "0                      1                       1                       1   \n",
            "1                      1                       1                       1   \n",
            "2                      1                       1                       1   \n",
            "3                      1                       1                       1   \n",
            "4                      1                       1                       1   \n",
            "\n",
            "   player2_R_ankle_x_flag  player2_R_ankle_y_flag  ball_x_flag  ball_y_flag  \n",
            "0                       1                       1            0            0  \n",
            "1                       1                       1            0            0  \n",
            "2                       1                       1            0            0  \n",
            "3                       1                       1            0            0  \n",
            "4                       1                       1            0            0  \n",
            "\n",
            "[5 rows x 117 columns]\n"
          ]
        }
      ],
      "source": [
        "input_xml_path = '/content/drive/MyDrive/PRIM/dataset/inputs/alatn.xml'\n",
        "output_csv_path = '/content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/alatn.xml'\n",
        "tree = preprocess.load_xml(input_xml_path)\n",
        "extracted_data = preprocess.extract_data_from_input(tree)\n",
        "df = preprocess.data_to_dataframe(extracted_data)\n",
        "df_interpolated = preprocess.interpolate_data_with_flag(df)\n",
        "print(\"Interpolated DataFrame:\")\n",
        "print(df_interpolated.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "091P_B8tWyO0",
        "outputId": "d8033170-62e3-4dd4-c3dd-41b594b3d201"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              frame  player1_nose_x  player1_nose_y  player1_L_shoulder_x  \\\n",
            "count  20040.000000    20040.000000    20040.000000          20040.000000   \n",
            "mean   10019.500000      561.418585      315.148403            572.114338   \n",
            "std     5785.194033      335.890725      119.352498            342.547021   \n",
            "min        0.000000       -9.860000        0.000000              0.000000   \n",
            "25%     5009.750000      335.687500      325.500000            340.000000   \n",
            "50%    10019.500000      476.500000      345.000000            498.500000   \n",
            "75%    15029.250000      868.000000      369.000000            889.500000   \n",
            "max    20039.000000     1288.000000      728.000000           1283.000000   \n",
            "\n",
            "       player1_L_shoulder_y  player1_R_shoulder_x  player1_R_shoulder_y  \\\n",
            "count          20040.000000          20040.000000          20040.000000   \n",
            "mean             349.044336            582.946604            347.471532   \n",
            "std              132.335110            376.882773            131.210147   \n",
            "min                0.000000             -8.120000              0.000000   \n",
            "25%              354.500000            300.000000            356.000000   \n",
            "50%              388.500000            490.500000            386.500000   \n",
            "75%              410.000000            950.000000            408.000000   \n",
            "max              718.000000           1299.000000            690.000000   \n",
            "\n",
            "       player1_L_elbow_x  player1_L_elbow_y  player1_R_elbow_x  ...  \\\n",
            "count       20040.000000       20040.000000       20040.000000  ...   \n",
            "mean          567.458959         398.956861         582.088049  ...   \n",
            "std           333.474275         155.371702         381.750401  ...   \n",
            "min             0.000000           0.000000          -2.310000  ...   \n",
            "25%           349.000000         390.500000         286.500000  ...   \n",
            "50%           498.750000         424.000000         492.750000  ...   \n",
            "75%           875.000000         492.500000         955.000000  ...   \n",
            "max          1283.000000         744.000000        1284.000000  ...   \n",
            "\n",
            "       player2_L_knee_x_flag  player2_L_knee_y_flag  player2_R_knee_x_flag  \\\n",
            "count           20040.000000           20040.000000           20040.000000   \n",
            "mean                0.966816               0.966816               0.966816   \n",
            "std                 0.179120               0.179120               0.179120   \n",
            "min                 0.000000               0.000000               0.000000   \n",
            "25%                 1.000000               1.000000               1.000000   \n",
            "50%                 1.000000               1.000000               1.000000   \n",
            "75%                 1.000000               1.000000               1.000000   \n",
            "max                 1.000000               1.000000               1.000000   \n",
            "\n",
            "       player2_R_knee_y_flag  player2_L_ankle_x_flag  player2_L_ankle_y_flag  \\\n",
            "count           20040.000000            20040.000000            20040.000000   \n",
            "mean                0.966816                0.966816                0.966816   \n",
            "std                 0.179120                0.179120                0.179120   \n",
            "min                 0.000000                0.000000                0.000000   \n",
            "25%                 1.000000                1.000000                1.000000   \n",
            "50%                 1.000000                1.000000                1.000000   \n",
            "75%                 1.000000                1.000000                1.000000   \n",
            "max                 1.000000                1.000000                1.000000   \n",
            "\n",
            "       player2_R_ankle_x_flag  player2_R_ankle_y_flag   ball_x_flag  \\\n",
            "count            20040.000000            20040.000000  20040.000000   \n",
            "mean                 0.966816                0.966816      0.302445   \n",
            "std                  0.179120                0.179120      0.459328   \n",
            "min                  0.000000                0.000000      0.000000   \n",
            "25%                  1.000000                1.000000      0.000000   \n",
            "50%                  1.000000                1.000000      0.000000   \n",
            "75%                  1.000000                1.000000      1.000000   \n",
            "max                  1.000000                1.000000      1.000000   \n",
            "\n",
            "        ball_y_flag  \n",
            "count  20040.000000  \n",
            "mean       0.302445  \n",
            "std        0.459328  \n",
            "min        0.000000  \n",
            "25%        0.000000  \n",
            "50%        0.000000  \n",
            "75%        1.000000  \n",
            "max        1.000000  \n",
            "\n",
            "[8 rows x 117 columns]\n"
          ]
        }
      ],
      "source": [
        "print(df_interpolated.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFQWR5fVXbIY",
        "outputId": "5343eacb-20da-4b7b-b191-3fac3b894074"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(20040, 117)\n"
          ]
        }
      ],
      "source": [
        "print(df_interpolated.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQTGkVbAXxtZ",
        "outputId": "d9831a33-f7c0-4cf8-db50-23ddcb8a5185"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Interpolated DataFrame:\n",
            "              frame  player1_nose_x  player1_nose_y  player1_L_shoulder_x  \\\n",
            "count  20040.000000    20040.000000    20040.000000          20040.000000   \n",
            "mean   10019.500000      602.476395      360.532098            612.359920   \n",
            "std     5785.194033      331.380278       34.847042            339.587165   \n",
            "min        0.000000       -9.860000      312.000000              1.090000   \n",
            "25%     5009.750000      343.250000      339.000000            350.500000   \n",
            "50%    10019.500000      647.500000      350.000000            620.750000   \n",
            "75%    15029.250000      877.500000      377.500000            897.000000   \n",
            "max    20039.000000     1288.000000      728.000000           1283.000000   \n",
            "\n",
            "       player1_L_shoulder_y  player1_R_shoulder_x  player1_R_shoulder_y  \\\n",
            "count          20040.000000          20040.000000          20040.000000   \n",
            "mean             405.660080            626.400971            404.637013   \n",
            "std               50.480492            370.239257             50.643185   \n",
            "min              335.000000             -8.120000            340.000000   \n",
            "25%              364.500000            311.000000            365.000000   \n",
            "50%              401.000000            662.500000            399.500000   \n",
            "75%              428.500000            960.000000            421.000000   \n",
            "max              718.000000           1299.000000            690.000000   \n",
            "\n",
            "       player1_L_elbow_x  player1_L_elbow_y  player1_R_elbow_x  ...  \\\n",
            "count       20040.000000       20040.000000       20040.000000  ...   \n",
            "mean          608.554252         469.341567         627.216644  ...   \n",
            "std           328.756045          76.570101         372.302190  ...   \n",
            "min             5.340000         346.000000          -2.310000  ...   \n",
            "25%           360.250000         398.500000         298.750000  ...   \n",
            "50%           604.000000         472.500000         655.000000  ...   \n",
            "75%           882.000000         508.000000         968.500000  ...   \n",
            "max          1283.000000         744.000000        1284.000000  ...   \n",
            "\n",
            "             ball_x        ball_y  table_corner1_x  table_corner1_y  \\\n",
            "count  20040.000000  20040.000000     20040.000000     20040.000000   \n",
            "mean     598.612369    472.994421       252.060029       477.390829   \n",
            "std      172.128389     71.228589         6.455150         0.417538   \n",
            "min        7.890000    127.279999       165.119995       473.880005   \n",
            "25%      455.072994    429.206702       252.589996       477.399994   \n",
            "50%      627.539978    473.532410       252.589996       477.399994   \n",
            "75%      734.126777    509.809097       252.589996       477.399994   \n",
            "max     1085.349976    717.840027       257.890015       482.760010   \n",
            "\n",
            "       table_corner2_x  table_corner2_y  table_corner3_x  table_corner3_y  \\\n",
            "count     20040.000000     20040.000000     20040.000000     20040.000000   \n",
            "mean        486.141515       451.024623       878.776578       511.054460   \n",
            "std           5.240547         0.287102         5.604028         0.320026   \n",
            "min         416.940002       448.450012       803.940002       509.559998   \n",
            "25%         486.470001       451.010010       879.270020       511.000000   \n",
            "50%         486.470001       451.010010       879.270020       511.000000   \n",
            "75%         486.470001       451.010010       879.270020       511.000000   \n",
            "max         494.630005       455.130005       883.539978       512.739990   \n",
            "\n",
            "       table_corner4_x  table_corner4_y  \n",
            "count     20040.000000     20040.000000  \n",
            "mean        645.648333       567.039960  \n",
            "std           6.577346         0.392310  \n",
            "min         563.700012       565.549988  \n",
            "25%         646.570007       566.979980  \n",
            "50%         646.570007       566.979980  \n",
            "75%         646.570007       566.979980  \n",
            "max         646.570007       572.030029  \n",
            "\n",
            "[8 rows x 63 columns]\n"
          ]
        }
      ],
      "source": [
        "df_interpolated_ = preprocess.interpolate_data(df)\n",
        "print(\"Interpolated DataFrame:\")\n",
        "print(df_interpolated_.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfpW85UWYKbL",
        "outputId": "a877231f-1270-4ba9-fdc8-ce22717d6bf6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(20040, 63)\n"
          ]
        }
      ],
      "source": [
        "print(df_interpolated_.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zEFJwuuYSae",
        "outputId": "4478a696-b716-406a-c13b-6dcdd4c81b46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " DataFrame:\n",
            "           frame_id      player 1      player 2         serve     let serve  \\\n",
            "count  20040.000000  20040.000000  20040.000000  20040.000000  20040.000000   \n",
            "mean   10019.500000      0.004741      0.005090      0.001846      0.000050   \n",
            "std     5785.194033      0.068690      0.071163      0.042930      0.007064   \n",
            "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
            "25%     5009.750000      0.000000      0.000000      0.000000      0.000000   \n",
            "50%    10019.500000      0.000000      0.000000      0.000000      0.000000   \n",
            "75%    15029.250000      0.000000      0.000000      0.000000      0.000000   \n",
            "max    20039.000000      1.000000      1.000000      1.000000      1.000000   \n",
            "\n",
            "         void serve     ball pass         point       mistake      forehand  \\\n",
            "count  20040.000000  20040.000000  20040.000000  20040.000000  20040.000000   \n",
            "mean       0.000050      0.001148      0.000449      0.001547      0.003643   \n",
            "std        0.007064      0.033859      0.021188      0.039301      0.060246   \n",
            "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
            "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
            "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
            "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
            "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
            "\n",
            "           backhand  \n",
            "count  20040.000000  \n",
            "mean       0.006138  \n",
            "std        0.078105  \n",
            "min        0.000000  \n",
            "25%        0.000000  \n",
            "50%        0.000000  \n",
            "75%        0.000000  \n",
            "max        1.000000  \n"
          ]
        }
      ],
      "source": [
        "output_xml_path = '/content/drive/MyDrive/PRIM/dataset/outputs/alatn.xml'\n",
        "output_csv_path = '/content/drive/MyDrive/PRIM/dataset/inputs/test1.csv'\n",
        "tree = preprocess.load_xml(output_xml_path)\n",
        "extracted_data = preprocess.extract_data_from_output(tree, \"Person\")\n",
        "df = preprocess.data_to_dataframe(extracted_data)\n",
        "print(\" DataFrame:\")\n",
        "print(df.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAX13WVlZU8V",
        "outputId": "066033e2-ee57-438b-836c-4a0315be5a63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           frame_id      player 1      player 2         serve     let serve  \\\n",
            "count  20040.000000  20040.000000  20040.000000  20040.000000  20040.000000   \n",
            "mean   10019.500000      0.004741      0.005090      0.001846      0.000050   \n",
            "std     5785.194033      0.068690      0.071163      0.042930      0.007064   \n",
            "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
            "25%     5009.750000      0.000000      0.000000      0.000000      0.000000   \n",
            "50%    10019.500000      0.000000      0.000000      0.000000      0.000000   \n",
            "75%    15029.250000      0.000000      0.000000      0.000000      0.000000   \n",
            "max    20039.000000      1.000000      1.000000      1.000000      1.000000   \n",
            "\n",
            "         void serve     ball pass         point       mistake      forehand  \\\n",
            "count  20040.000000  20040.000000  20040.000000  20040.000000  20040.000000   \n",
            "mean       0.000050      0.001148      0.000449      0.001547      0.003643   \n",
            "std        0.007064      0.033859      0.021188      0.039301      0.060246   \n",
            "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
            "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
            "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
            "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
            "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
            "\n",
            "           backhand  \n",
            "count  20040.000000  \n",
            "mean       0.006138  \n",
            "std        0.078105  \n",
            "min        0.000000  \n",
            "25%        0.000000  \n",
            "50%        0.000000  \n",
            "75%        0.000000  \n",
            "max        1.000000  \n"
          ]
        }
      ],
      "source": [
        "print(df.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENuo3sSZdSl_"
      },
      "outputs": [],
      "source": [
        "%matplotlib notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "ATPPgHCuZaMu",
        "outputId": "07418fd8-83d4-4046-a530-03537675d173"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "/* Put everything inside the global mpl namespace */\n/* global mpl */\nwindow.mpl = {};\n\nmpl.get_websocket_type = function () {\n    if (typeof WebSocket !== 'undefined') {\n        return WebSocket;\n    } else if (typeof MozWebSocket !== 'undefined') {\n        return MozWebSocket;\n    } else {\n        alert(\n            'Your browser does not have WebSocket support. ' +\n                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n                'Firefox 4 and 5 are also supported but you ' +\n                'have to enable WebSockets in about:config.'\n        );\n    }\n};\n\nmpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n    this.id = figure_id;\n\n    this.ws = websocket;\n\n    this.supports_binary = this.ws.binaryType !== undefined;\n\n    if (!this.supports_binary) {\n        var warnings = document.getElementById('mpl-warnings');\n        if (warnings) {\n            warnings.style.display = 'block';\n            warnings.textContent =\n                'This browser does not support binary websocket messages. ' +\n                'Performance may be slow.';\n        }\n    }\n\n    this.imageObj = new Image();\n\n    this.context = undefined;\n    this.message = undefined;\n    this.canvas = undefined;\n    this.rubberband_canvas = undefined;\n    this.rubberband_context = undefined;\n    this.format_dropdown = undefined;\n\n    this.image_mode = 'full';\n\n    this.root = document.createElement('div');\n    this.root.setAttribute('style', 'display: inline-block');\n    this._root_extra_style(this.root);\n\n    parent_element.appendChild(this.root);\n\n    this._init_header(this);\n    this._init_canvas(this);\n    this._init_toolbar(this);\n\n    var fig = this;\n\n    this.waiting = false;\n\n    this.ws.onopen = function () {\n        fig.send_message('supports_binary', { value: fig.supports_binary });\n        fig.send_message('send_image_mode', {});\n        if (fig.ratio !== 1) {\n            fig.send_message('set_device_pixel_ratio', {\n                device_pixel_ratio: fig.ratio,\n            });\n        }\n        fig.send_message('refresh', {});\n    };\n\n    this.imageObj.onload = function () {\n        if (fig.image_mode === 'full') {\n            // Full images could contain transparency (where diff images\n            // almost always do), so we need to clear the canvas so that\n            // there is no ghosting.\n            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n        }\n        fig.context.drawImage(fig.imageObj, 0, 0);\n    };\n\n    this.imageObj.onunload = function () {\n        fig.ws.close();\n    };\n\n    this.ws.onmessage = this._make_on_message_function(this);\n\n    this.ondownload = ondownload;\n};\n\nmpl.figure.prototype._init_header = function () {\n    var titlebar = document.createElement('div');\n    titlebar.classList =\n        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n    var titletext = document.createElement('div');\n    titletext.classList = 'ui-dialog-title';\n    titletext.setAttribute(\n        'style',\n        'width: 100%; text-align: center; padding: 3px;'\n    );\n    titlebar.appendChild(titletext);\n    this.root.appendChild(titlebar);\n    this.header = titletext;\n};\n\nmpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n\nmpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n\nmpl.figure.prototype._init_canvas = function () {\n    var fig = this;\n\n    var canvas_div = (this.canvas_div = document.createElement('div'));\n    canvas_div.setAttribute('tabindex', '0');\n    canvas_div.setAttribute(\n        'style',\n        'border: 1px solid #ddd;' +\n            'box-sizing: content-box;' +\n            'clear: both;' +\n            'min-height: 1px;' +\n            'min-width: 1px;' +\n            'outline: 0;' +\n            'overflow: hidden;' +\n            'position: relative;' +\n            'resize: both;' +\n            'z-index: 2;'\n    );\n\n    function on_keyboard_event_closure(name) {\n        return function (event) {\n            return fig.key_event(event, name);\n        };\n    }\n\n    canvas_div.addEventListener(\n        'keydown',\n        on_keyboard_event_closure('key_press')\n    );\n    canvas_div.addEventListener(\n        'keyup',\n        on_keyboard_event_closure('key_release')\n    );\n\n    this._canvas_extra_style(canvas_div);\n    this.root.appendChild(canvas_div);\n\n    var canvas = (this.canvas = document.createElement('canvas'));\n    canvas.classList.add('mpl-canvas');\n    canvas.setAttribute(\n        'style',\n        'box-sizing: content-box;' +\n            'pointer-events: none;' +\n            'position: relative;' +\n            'z-index: 0;'\n    );\n\n    this.context = canvas.getContext('2d');\n\n    var backingStore =\n        this.context.backingStorePixelRatio ||\n        this.context.webkitBackingStorePixelRatio ||\n        this.context.mozBackingStorePixelRatio ||\n        this.context.msBackingStorePixelRatio ||\n        this.context.oBackingStorePixelRatio ||\n        this.context.backingStorePixelRatio ||\n        1;\n\n    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n\n    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n        'canvas'\n    ));\n    rubberband_canvas.setAttribute(\n        'style',\n        'box-sizing: content-box;' +\n            'left: 0;' +\n            'pointer-events: none;' +\n            'position: absolute;' +\n            'top: 0;' +\n            'z-index: 1;'\n    );\n\n    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n    if (this.ResizeObserver === undefined) {\n        if (window.ResizeObserver !== undefined) {\n            this.ResizeObserver = window.ResizeObserver;\n        } else {\n            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n            this.ResizeObserver = obs.ResizeObserver;\n        }\n    }\n\n    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n        var nentries = entries.length;\n        for (var i = 0; i < nentries; i++) {\n            var entry = entries[i];\n            var width, height;\n            if (entry.contentBoxSize) {\n                if (entry.contentBoxSize instanceof Array) {\n                    // Chrome 84 implements new version of spec.\n                    width = entry.contentBoxSize[0].inlineSize;\n                    height = entry.contentBoxSize[0].blockSize;\n                } else {\n                    // Firefox implements old version of spec.\n                    width = entry.contentBoxSize.inlineSize;\n                    height = entry.contentBoxSize.blockSize;\n                }\n            } else {\n                // Chrome <84 implements even older version of spec.\n                width = entry.contentRect.width;\n                height = entry.contentRect.height;\n            }\n\n            // Keep the size of the canvas and rubber band canvas in sync with\n            // the canvas container.\n            if (entry.devicePixelContentBoxSize) {\n                // Chrome 84 implements new version of spec.\n                canvas.setAttribute(\n                    'width',\n                    entry.devicePixelContentBoxSize[0].inlineSize\n                );\n                canvas.setAttribute(\n                    'height',\n                    entry.devicePixelContentBoxSize[0].blockSize\n                );\n            } else {\n                canvas.setAttribute('width', width * fig.ratio);\n                canvas.setAttribute('height', height * fig.ratio);\n            }\n            /* This rescales the canvas back to display pixels, so that it\n             * appears correct on HiDPI screens. */\n            canvas.style.width = width + 'px';\n            canvas.style.height = height + 'px';\n\n            rubberband_canvas.setAttribute('width', width);\n            rubberband_canvas.setAttribute('height', height);\n\n            // And update the size in Python. We ignore the initial 0/0 size\n            // that occurs as the element is placed into the DOM, which should\n            // otherwise not happen due to the minimum size styling.\n            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n                fig.request_resize(width, height);\n            }\n        }\n    });\n    this.resizeObserverInstance.observe(canvas_div);\n\n    function on_mouse_event_closure(name) {\n        /* User Agent sniffing is bad, but WebKit is busted:\n         * https://bugs.webkit.org/show_bug.cgi?id=144526\n         * https://bugs.webkit.org/show_bug.cgi?id=181818\n         * The worst that happens here is that they get an extra browser\n         * selection when dragging, if this check fails to catch them.\n         */\n        var UA = navigator.userAgent;\n        var isWebKit = /AppleWebKit/.test(UA) && !/Chrome/.test(UA);\n        if(isWebKit) {\n            return function (event) {\n                /* This prevents the web browser from automatically changing to\n                 * the text insertion cursor when the button is pressed. We\n                 * want to control all of the cursor setting manually through\n                 * the 'cursor' event from matplotlib */\n                event.preventDefault()\n                return fig.mouse_event(event, name);\n            };\n        } else {\n            return function (event) {\n                return fig.mouse_event(event, name);\n            };\n        }\n    }\n\n    canvas_div.addEventListener(\n        'mousedown',\n        on_mouse_event_closure('button_press')\n    );\n    canvas_div.addEventListener(\n        'mouseup',\n        on_mouse_event_closure('button_release')\n    );\n    canvas_div.addEventListener(\n        'dblclick',\n        on_mouse_event_closure('dblclick')\n    );\n    // Throttle sequential mouse events to 1 every 20ms.\n    canvas_div.addEventListener(\n        'mousemove',\n        on_mouse_event_closure('motion_notify')\n    );\n\n    canvas_div.addEventListener(\n        'mouseenter',\n        on_mouse_event_closure('figure_enter')\n    );\n    canvas_div.addEventListener(\n        'mouseleave',\n        on_mouse_event_closure('figure_leave')\n    );\n\n    canvas_div.addEventListener('wheel', function (event) {\n        if (event.deltaY < 0) {\n            event.step = 1;\n        } else {\n            event.step = -1;\n        }\n        on_mouse_event_closure('scroll')(event);\n    });\n\n    canvas_div.appendChild(canvas);\n    canvas_div.appendChild(rubberband_canvas);\n\n    this.rubberband_context = rubberband_canvas.getContext('2d');\n    this.rubberband_context.strokeStyle = '#000000';\n\n    this._resize_canvas = function (width, height, forward) {\n        if (forward) {\n            canvas_div.style.width = width + 'px';\n            canvas_div.style.height = height + 'px';\n        }\n    };\n\n    // Disable right mouse context menu.\n    canvas_div.addEventListener('contextmenu', function (_e) {\n        event.preventDefault();\n        return false;\n    });\n\n    function set_focus() {\n        canvas.focus();\n        canvas_div.focus();\n    }\n\n    window.setTimeout(set_focus, 100);\n};\n\nmpl.figure.prototype._init_toolbar = function () {\n    var fig = this;\n\n    var toolbar = document.createElement('div');\n    toolbar.classList = 'mpl-toolbar';\n    this.root.appendChild(toolbar);\n\n    function on_click_closure(name) {\n        return function (_event) {\n            return fig.toolbar_button_onclick(name);\n        };\n    }\n\n    function on_mouseover_closure(tooltip) {\n        return function (event) {\n            if (!event.currentTarget.disabled) {\n                return fig.toolbar_button_onmouseover(tooltip);\n            }\n        };\n    }\n\n    fig.buttons = {};\n    var buttonGroup = document.createElement('div');\n    buttonGroup.classList = 'mpl-button-group';\n    for (var toolbar_ind in mpl.toolbar_items) {\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) {\n            /* Instead of a spacer, we start a new button group. */\n            if (buttonGroup.hasChildNodes()) {\n                toolbar.appendChild(buttonGroup);\n            }\n            buttonGroup = document.createElement('div');\n            buttonGroup.classList = 'mpl-button-group';\n            continue;\n        }\n\n        var button = (fig.buttons[name] = document.createElement('button'));\n        button.classList = 'mpl-widget';\n        button.setAttribute('role', 'button');\n        button.setAttribute('aria-disabled', 'false');\n        button.addEventListener('click', on_click_closure(method_name));\n        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n\n        var icon_img = document.createElement('img');\n        icon_img.src = '_images/' + image + '.png';\n        icon_img.srcset = '_images/' + image + '_large.png 2x';\n        icon_img.alt = tooltip;\n        button.appendChild(icon_img);\n\n        buttonGroup.appendChild(button);\n    }\n\n    if (buttonGroup.hasChildNodes()) {\n        toolbar.appendChild(buttonGroup);\n    }\n\n    var fmt_picker = document.createElement('select');\n    fmt_picker.classList = 'mpl-widget';\n    toolbar.appendChild(fmt_picker);\n    this.format_dropdown = fmt_picker;\n\n    for (var ind in mpl.extensions) {\n        var fmt = mpl.extensions[ind];\n        var option = document.createElement('option');\n        option.selected = fmt === mpl.default_extension;\n        option.innerHTML = fmt;\n        fmt_picker.appendChild(option);\n    }\n\n    var status_bar = document.createElement('span');\n    status_bar.classList = 'mpl-message';\n    toolbar.appendChild(status_bar);\n    this.message = status_bar;\n};\n\nmpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n    // which will in turn request a refresh of the image.\n    this.send_message('resize', { width: x_pixels, height: y_pixels });\n};\n\nmpl.figure.prototype.send_message = function (type, properties) {\n    properties['type'] = type;\n    properties['figure_id'] = this.id;\n    this.ws.send(JSON.stringify(properties));\n};\n\nmpl.figure.prototype.send_draw_message = function () {\n    if (!this.waiting) {\n        this.waiting = true;\n        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n    }\n};\n\nmpl.figure.prototype.handle_save = function (fig, _msg) {\n    var format_dropdown = fig.format_dropdown;\n    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n    fig.ondownload(fig, format);\n};\n\nmpl.figure.prototype.handle_resize = function (fig, msg) {\n    var size = msg['size'];\n    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n        fig._resize_canvas(size[0], size[1], msg['forward']);\n        fig.send_message('refresh', {});\n    }\n};\n\nmpl.figure.prototype.handle_rubberband = function (fig, msg) {\n    var x0 = msg['x0'] / fig.ratio;\n    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n    var x1 = msg['x1'] / fig.ratio;\n    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n    x0 = Math.floor(x0) + 0.5;\n    y0 = Math.floor(y0) + 0.5;\n    x1 = Math.floor(x1) + 0.5;\n    y1 = Math.floor(y1) + 0.5;\n    var min_x = Math.min(x0, x1);\n    var min_y = Math.min(y0, y1);\n    var width = Math.abs(x1 - x0);\n    var height = Math.abs(y1 - y0);\n\n    fig.rubberband_context.clearRect(\n        0,\n        0,\n        fig.canvas.width / fig.ratio,\n        fig.canvas.height / fig.ratio\n    );\n\n    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n};\n\nmpl.figure.prototype.handle_figure_label = function (fig, msg) {\n    // Updates the figure title.\n    fig.header.textContent = msg['label'];\n};\n\nmpl.figure.prototype.handle_cursor = function (fig, msg) {\n    fig.canvas_div.style.cursor = msg['cursor'];\n};\n\nmpl.figure.prototype.handle_message = function (fig, msg) {\n    fig.message.textContent = msg['message'];\n};\n\nmpl.figure.prototype.handle_draw = function (fig, _msg) {\n    // Request the server to send over a new figure.\n    fig.send_draw_message();\n};\n\nmpl.figure.prototype.handle_image_mode = function (fig, msg) {\n    fig.image_mode = msg['mode'];\n};\n\nmpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n    for (var key in msg) {\n        if (!(key in fig.buttons)) {\n            continue;\n        }\n        fig.buttons[key].disabled = !msg[key];\n        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n    }\n};\n\nmpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n    if (msg['mode'] === 'PAN') {\n        fig.buttons['Pan'].classList.add('active');\n        fig.buttons['Zoom'].classList.remove('active');\n    } else if (msg['mode'] === 'ZOOM') {\n        fig.buttons['Pan'].classList.remove('active');\n        fig.buttons['Zoom'].classList.add('active');\n    } else {\n        fig.buttons['Pan'].classList.remove('active');\n        fig.buttons['Zoom'].classList.remove('active');\n    }\n};\n\nmpl.figure.prototype.updated_canvas_event = function () {\n    // Called whenever the canvas gets updated.\n    this.send_message('ack', {});\n};\n\n// A function to construct a web socket function for onmessage handling.\n// Called in the figure constructor.\nmpl.figure.prototype._make_on_message_function = function (fig) {\n    return function socket_on_message(evt) {\n        if (evt.data instanceof Blob) {\n            var img = evt.data;\n            if (img.type !== 'image/png') {\n                /* FIXME: We get \"Resource interpreted as Image but\n                 * transferred with MIME type text/plain:\" errors on\n                 * Chrome.  But how to set the MIME type?  It doesn't seem\n                 * to be part of the websocket stream */\n                img.type = 'image/png';\n            }\n\n            /* Free the memory for the previous frames */\n            if (fig.imageObj.src) {\n                (window.URL || window.webkitURL).revokeObjectURL(\n                    fig.imageObj.src\n                );\n            }\n\n            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n                img\n            );\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        } else if (\n            typeof evt.data === 'string' &&\n            evt.data.slice(0, 21) === 'data:image/png;base64'\n        ) {\n            fig.imageObj.src = evt.data;\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        }\n\n        var msg = JSON.parse(evt.data);\n        var msg_type = msg['type'];\n\n        // Call the  \"handle_{type}\" callback, which takes\n        // the figure and JSON message as its only arguments.\n        try {\n            var callback = fig['handle_' + msg_type];\n        } catch (e) {\n            console.log(\n                \"No handler for the '\" + msg_type + \"' message type: \",\n                msg\n            );\n            return;\n        }\n\n        if (callback) {\n            try {\n                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n                callback(fig, msg);\n            } catch (e) {\n                console.log(\n                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n                    e,\n                    e.stack,\n                    msg\n                );\n            }\n        }\n    };\n};\n\nfunction getModifiers(event) {\n    var mods = [];\n    if (event.ctrlKey) {\n        mods.push('ctrl');\n    }\n    if (event.altKey) {\n        mods.push('alt');\n    }\n    if (event.shiftKey) {\n        mods.push('shift');\n    }\n    if (event.metaKey) {\n        mods.push('meta');\n    }\n    return mods;\n}\n\n/*\n * return a copy of an object with only non-object keys\n * we need this to avoid circular references\n * https://stackoverflow.com/a/24161582/3208463\n */\nfunction simpleKeys(original) {\n    return Object.keys(original).reduce(function (obj, key) {\n        if (typeof original[key] !== 'object') {\n            obj[key] = original[key];\n        }\n        return obj;\n    }, {});\n}\n\nmpl.figure.prototype.mouse_event = function (event, name) {\n    if (name === 'button_press') {\n        this.canvas.focus();\n        this.canvas_div.focus();\n    }\n\n    // from https://stackoverflow.com/q/1114465\n    var boundingRect = this.canvas.getBoundingClientRect();\n    var x = (event.clientX - boundingRect.left) * this.ratio;\n    var y = (event.clientY - boundingRect.top) * this.ratio;\n\n    this.send_message(name, {\n        x: x,\n        y: y,\n        button: event.button,\n        step: event.step,\n        modifiers: getModifiers(event),\n        guiEvent: simpleKeys(event),\n    });\n\n    return false;\n};\n\nmpl.figure.prototype._key_event_extra = function (_event, _name) {\n    // Handle any extra behaviour associated with a key event\n};\n\nmpl.figure.prototype.key_event = function (event, name) {\n    // Prevent repeat events\n    if (name === 'key_press') {\n        if (event.key === this._key) {\n            return;\n        } else {\n            this._key = event.key;\n        }\n    }\n    if (name === 'key_release') {\n        this._key = null;\n    }\n\n    var value = '';\n    if (event.ctrlKey && event.key !== 'Control') {\n        value += 'ctrl+';\n    }\n    else if (event.altKey && event.key !== 'Alt') {\n        value += 'alt+';\n    }\n    else if (event.shiftKey && event.key !== 'Shift') {\n        value += 'shift+';\n    }\n\n    value += 'k' + event.key;\n\n    this._key_event_extra(event, name);\n\n    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n    return false;\n};\n\nmpl.figure.prototype.toolbar_button_onclick = function (name) {\n    if (name === 'download') {\n        this.handle_save(this, null);\n    } else {\n        this.send_message('toolbar_button', { name: name });\n    }\n};\n\nmpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n    this.message.textContent = tooltip;\n};\n\n///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n// prettier-ignore\nvar _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\nmpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o\", \"download\"]];\n\nmpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\", \"webp\"];\n\nmpl.default_extension = \"png\";/* global mpl */\n\nvar comm_websocket_adapter = function (comm) {\n    // Create a \"websocket\"-like object which calls the given IPython comm\n    // object with the appropriate methods. Currently this is a non binary\n    // socket, so there is still some room for performance tuning.\n    var ws = {};\n\n    ws.binaryType = comm.kernel.ws.binaryType;\n    ws.readyState = comm.kernel.ws.readyState;\n    function updateReadyState(_event) {\n        if (comm.kernel.ws) {\n            ws.readyState = comm.kernel.ws.readyState;\n        } else {\n            ws.readyState = 3; // Closed state.\n        }\n    }\n    comm.kernel.ws.addEventListener('open', updateReadyState);\n    comm.kernel.ws.addEventListener('close', updateReadyState);\n    comm.kernel.ws.addEventListener('error', updateReadyState);\n\n    ws.close = function () {\n        comm.close();\n    };\n    ws.send = function (m) {\n        //console.log('sending', m);\n        comm.send(m);\n    };\n    // Register the callback with on_msg.\n    comm.on_msg(function (msg) {\n        //console.log('receiving', msg['content']['data'], msg);\n        var data = msg['content']['data'];\n        if (data['blob'] !== undefined) {\n            data = {\n                data: new Blob(msg['buffers'], { type: data['blob'] }),\n            };\n        }\n        // Pass the mpl event to the overridden (by mpl) onmessage function.\n        ws.onmessage(data);\n    });\n    return ws;\n};\n\nmpl.mpl_figure_comm = function (comm, msg) {\n    // This is the function which gets called when the mpl process\n    // starts-up an IPython Comm through the \"matplotlib\" channel.\n\n    var id = msg.content.data.id;\n    // Get hold of the div created by the display call when the Comm\n    // socket was opened in Python.\n    var element = document.getElementById(id);\n    var ws_proxy = comm_websocket_adapter(comm);\n\n    function ondownload(figure, _format) {\n        window.open(figure.canvas.toDataURL());\n    }\n\n    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n\n    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n    // web socket which is closed, not our websocket->open comm proxy.\n    ws_proxy.onopen();\n\n    fig.parent_element = element;\n    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n    if (!fig.cell_info) {\n        console.error('Failed to find cell for figure', id, fig);\n        return;\n    }\n    fig.cell_info[0].output_area.element.on(\n        'cleared',\n        { fig: fig },\n        fig._remove_fig_handler\n    );\n};\n\nmpl.figure.prototype.handle_close = function (fig, msg) {\n    var width = fig.canvas.width / fig.ratio;\n    fig.cell_info[0].output_area.element.off(\n        'cleared',\n        fig._remove_fig_handler\n    );\n    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n\n    // Update the output cell to use the data from the current canvas.\n    fig.push_to_output();\n    var dataURL = fig.canvas.toDataURL();\n    // Re-enable the keyboard manager in IPython - without this line, in FF,\n    // the notebook keyboard shortcuts fail.\n    IPython.keyboard_manager.enable();\n    fig.parent_element.innerHTML =\n        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n    fig.close_ws(fig, msg);\n};\n\nmpl.figure.prototype.close_ws = function (fig, msg) {\n    fig.send_message('closing', msg);\n    // fig.ws.close()\n};\n\nmpl.figure.prototype.push_to_output = function (_remove_interactive) {\n    // Turn the data on the canvas into data in the output cell.\n    var width = this.canvas.width / this.ratio;\n    var dataURL = this.canvas.toDataURL();\n    this.cell_info[1]['text/html'] =\n        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n};\n\nmpl.figure.prototype.updated_canvas_event = function () {\n    // Tell IPython that the notebook contents must change.\n    IPython.notebook.set_dirty(true);\n    this.send_message('ack', {});\n    var fig = this;\n    // Wait a second, then push the new image to the DOM so\n    // that it is saved nicely (might be nice to debounce this).\n    setTimeout(function () {\n        fig.push_to_output();\n    }, 1000);\n};\n\nmpl.figure.prototype._init_toolbar = function () {\n    var fig = this;\n\n    var toolbar = document.createElement('div');\n    toolbar.classList = 'btn-toolbar';\n    this.root.appendChild(toolbar);\n\n    function on_click_closure(name) {\n        return function (_event) {\n            return fig.toolbar_button_onclick(name);\n        };\n    }\n\n    function on_mouseover_closure(tooltip) {\n        return function (event) {\n            if (!event.currentTarget.disabled) {\n                return fig.toolbar_button_onmouseover(tooltip);\n            }\n        };\n    }\n\n    fig.buttons = {};\n    var buttonGroup = document.createElement('div');\n    buttonGroup.classList = 'btn-group';\n    var button;\n    for (var toolbar_ind in mpl.toolbar_items) {\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) {\n            /* Instead of a spacer, we start a new button group. */\n            if (buttonGroup.hasChildNodes()) {\n                toolbar.appendChild(buttonGroup);\n            }\n            buttonGroup = document.createElement('div');\n            buttonGroup.classList = 'btn-group';\n            continue;\n        }\n\n        button = fig.buttons[name] = document.createElement('button');\n        button.classList = 'btn btn-default';\n        button.href = '#';\n        button.title = name;\n        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n        button.addEventListener('click', on_click_closure(method_name));\n        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n        buttonGroup.appendChild(button);\n    }\n\n    if (buttonGroup.hasChildNodes()) {\n        toolbar.appendChild(buttonGroup);\n    }\n\n    // Add the status bar.\n    var status_bar = document.createElement('span');\n    status_bar.classList = 'mpl-message pull-right';\n    toolbar.appendChild(status_bar);\n    this.message = status_bar;\n\n    // Add the close button to the window.\n    var buttongrp = document.createElement('div');\n    buttongrp.classList = 'btn-group inline pull-right';\n    button = document.createElement('button');\n    button.classList = 'btn btn-mini btn-primary';\n    button.href = '#';\n    button.title = 'Stop Interaction';\n    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n    button.addEventListener('click', function (_evt) {\n        fig.handle_close(fig, {});\n    });\n    button.addEventListener(\n        'mouseover',\n        on_mouseover_closure('Stop Interaction')\n    );\n    buttongrp.appendChild(button);\n    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n};\n\nmpl.figure.prototype._remove_fig_handler = function (event) {\n    var fig = event.data.fig;\n    if (event.target !== this) {\n        // Ignore bubbled events from children.\n        return;\n    }\n    fig.close_ws(fig, {});\n};\n\nmpl.figure.prototype._root_extra_style = function (el) {\n    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n};\n\nmpl.figure.prototype._canvas_extra_style = function (el) {\n    // this is important to make the div 'focusable\n    el.setAttribute('tabindex', 0);\n    // reach out to IPython and tell the keyboard manager to turn it's self\n    // off when our div gets focus\n\n    // location in version 3\n    if (IPython.notebook.keyboard_manager) {\n        IPython.notebook.keyboard_manager.register_events(el);\n    } else {\n        // location in version 2\n        IPython.keyboard_manager.register_events(el);\n    }\n};\n\nmpl.figure.prototype._key_event_extra = function (event, _name) {\n    // Check for shift+enter\n    if (event.shiftKey && event.which === 13) {\n        this.canvas_div.blur();\n        // select the cell after this one\n        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n        IPython.notebook.select(index + 1);\n    }\n};\n\nmpl.figure.prototype.handle_save = function (fig, _msg) {\n    fig.ondownload(fig, null);\n};\n\nmpl.find_output_cell = function (html_output) {\n    // Return the cell and output element which can be found *uniquely* in the notebook.\n    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n    // IPython event is triggered only after the cells have been serialised, which for\n    // our purposes (turning an active figure into a static one), is too late.\n    var cells = IPython.notebook.get_cells();\n    var ncells = cells.length;\n    for (var i = 0; i < ncells; i++) {\n        var cell = cells[i];\n        if (cell.cell_type === 'code') {\n            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n                var data = cell.output_area.outputs[j];\n                if (data.data) {\n                    // IPython >= 3 moved mimebundle to data attribute of output\n                    data = data.data;\n                }\n                if (data['text/html'] === html_output) {\n                    return [cell, data, j];\n                }\n            }\n        }\n    }\n};\n\n// Register the function which deals with the matplotlib target/channel.\n// The kernel may be null if the page has been refreshed.\nif (IPython.notebook.kernel !== null) {\n    IPython.notebook.kernel.comm_manager.register_target(\n        'matplotlib',\n        mpl.mpl_figure_comm\n    );\n}\n",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div id='a529ee55-f28b-420c-ba2a-22bfa124415b'></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-30-4e058231ec60>:81: MatplotlibDeprecationWarning: Setting data with a non sequence type is deprecated since 3.7 and will be remove two minor releases later\n",
            "  ball_point.set_data(ball_x, ball_y)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation\n",
        "\n",
        "def visualize_detailed_gameplay(coordinates_df, tags_df, save_animation=False):\n",
        "    \"\"\"\n",
        "    Visualize the gameplay with detailed points for players, ball, and table.\n",
        "\n",
        "    Parameters:\n",
        "    - coordinates_df (DataFrame): DataFrame containing coordinates.\n",
        "    - tags_df (DataFrame): DataFrame containing tags for each frame.\n",
        "    - save_animation (bool): If True, saves the animation as a .mp4 file.\n",
        "    \"\"\"\n",
        "    # Merge the DataFrames on the \"frame\" column !ba3d tinsach traja3ha on=\"frame\" !!!!!!\n",
        "    combined_df = pd.merge(coordinates_df, tags_df, left_on=\"frame\",right_on=\"frame_id\")\n",
        "\n",
        "    # Extract frame numbers\n",
        "    frames = combined_df[\"frame\"].unique()\n",
        "\n",
        "    # Create figure and axis\n",
        "    fig, ax = plt.subplots(figsize=(10, 8))\n",
        "    ax.set_xlim(0, 1920)  # Adjust based on your data range\n",
        "    ax.set_ylim(0, 1080)  # Adjust based on your data range\n",
        "    ax.invert_yaxis()\n",
        "    ax.set_title(\"Detailed Gameplay Visualization\")\n",
        "    ax.set_xlabel(\"X\")\n",
        "    ax.set_ylabel(\"Y\")\n",
        "\n",
        "    # Initialize plot elements for players, ball, and table\n",
        "    player1_points, = ax.plot([], [], 'ro', label=\"Player 1\", markersize=5)\n",
        "    player2_points, = ax.plot([], [], 'bo', label=\"Player 2\", markersize=5)\n",
        "    ball_point, = ax.plot([], [], 'go', label=\"Ball\", markersize=8)\n",
        "    table_points, = ax.plot([], [], 'mo-', label=\"Table Corners\", markersize=5)  # Line connecting corners\n",
        "    tag_text = ax.text(0.5, 1.05, '', transform=ax.transAxes, ha=\"center\", fontsize=12)\n",
        "\n",
        "    # Initialize the plot\n",
        "    def init():\n",
        "        player1_points.set_data([], [])\n",
        "        player2_points.set_data([], [])\n",
        "        ball_point.set_data([], [])\n",
        "        table_points.set_data([], [])\n",
        "        tag_text.set_text('')\n",
        "        return player1_points, player2_points, ball_point, table_points, tag_text\n",
        "\n",
        "    # Update the plot for each frame\n",
        "    def update(frame):\n",
        "        # Filter data for the current frame\n",
        "        data = combined_df[combined_df[\"frame\"] == frame]\n",
        "\n",
        "        # Extract Player 1 keypoints\n",
        "        player1_x = [data[f\"player1_{part}_x\"].values[0] for part in\n",
        "                     [\"nose\", \"L_shoulder\", \"R_shoulder\", \"L_elbow\", \"R_elbow\",\n",
        "                      \"L_wrist\", \"R_wrist\", \"L_hip\", \"R_hip\", \"L_knee\", \"R_knee\",\n",
        "                      \"L_ankle\", \"R_ankle\"]]\n",
        "        player1_y = [data[f\"player1_{part}_y\"].values[0] for part in\n",
        "                     [\"nose\", \"L_shoulder\", \"R_shoulder\", \"L_elbow\", \"R_elbow\",\n",
        "                      \"L_wrist\", \"R_wrist\", \"L_hip\", \"R_hip\", \"L_knee\", \"R_knee\",\n",
        "                      \"L_ankle\", \"R_ankle\"]]\n",
        "\n",
        "        # Extract Player 2 keypoints\n",
        "        player2_x = [data[f\"player2_{part}_x\"].values[0] for part in\n",
        "                     [\"nose\", \"L_shoulder\", \"R_shoulder\", \"L_elbow\", \"R_elbow\",\n",
        "                      \"L_wrist\", \"R_wrist\", \"L_hip\", \"R_hip\", \"L_knee\", \"R_knee\",\n",
        "                      \"L_ankle\", \"R_ankle\"]]\n",
        "        player2_y = [data[f\"player2_{part}_y\"].values[0] for part in\n",
        "                     [\"nose\", \"L_shoulder\", \"R_shoulder\", \"L_elbow\", \"R_elbow\",\n",
        "                      \"L_wrist\", \"R_wrist\", \"L_hip\", \"R_hip\", \"L_knee\", \"R_knee\",\n",
        "                      \"L_ankle\", \"R_ankle\"]]\n",
        "\n",
        "        # Extract Ball position\n",
        "        ball_x = data[\"ball_x\"].values[0]\n",
        "        ball_y = data[\"ball_y\"].values[0]\n",
        "\n",
        "        # Extract Table corners\n",
        "        table_x = [data[f\"table_corner{i}_x\"].values[0] for i in range(1, 5)]\n",
        "        table_y = [data[f\"table_corner{i}_y\"].values[0] for i in range(1, 5)]\n",
        "\n",
        "        # Update plot data\n",
        "        player1_points.set_data(player1_x, player1_y)\n",
        "        player2_points.set_data(player2_x, player2_y)\n",
        "        ball_point.set_data(ball_x, ball_y)\n",
        "        table_points.set_data(table_x + [table_x[0]], table_y + [table_y[0]])  # Loop to close table\n",
        "\n",
        "        # Update tags\n",
        "        frame_tags = combined_df[combined_df[\"frame\"] <= frame].tail(4)\n",
        "        if not frame_tags.empty:\n",
        "          latest_tags = \", \".join([col for col in tags_df.columns if frame_tags.iloc[-1][col] == 1])\n",
        "          tag_text.set_text(f\"Frame: {frame} | Tags: {latest_tags}\")\n",
        "\n",
        "        return player1_points, player2_points, ball_point, table_points, tag_text\n",
        "\n",
        "    # Create the animation\n",
        "    ani = FuncAnimation(fig, update, frames=frames, init_func=init, blit=True, interval=33)\n",
        "\n",
        "    # Save or display the animation\n",
        "    if save_animation:\n",
        "        ani.save(\"/content/drive/MyDrive/PRIM/detailed_gameplay.mp4\", writer=\"ffmpeg\")\n",
        "    else:\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "visualize_detailed_gameplay(df_interpolated_, df,True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "7-qXGAb6bW8B",
        "outputId": "5214f24e-a0ce-4179-fa39-ee741c93a218"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "/* Put everything inside the global mpl namespace */\n/* global mpl */\nwindow.mpl = {};\n\nmpl.get_websocket_type = function () {\n    if (typeof WebSocket !== 'undefined') {\n        return WebSocket;\n    } else if (typeof MozWebSocket !== 'undefined') {\n        return MozWebSocket;\n    } else {\n        alert(\n            'Your browser does not have WebSocket support. ' +\n                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n                'Firefox 4 and 5 are also supported but you ' +\n                'have to enable WebSockets in about:config.'\n        );\n    }\n};\n\nmpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n    this.id = figure_id;\n\n    this.ws = websocket;\n\n    this.supports_binary = this.ws.binaryType !== undefined;\n\n    if (!this.supports_binary) {\n        var warnings = document.getElementById('mpl-warnings');\n        if (warnings) {\n            warnings.style.display = 'block';\n            warnings.textContent =\n                'This browser does not support binary websocket messages. ' +\n                'Performance may be slow.';\n        }\n    }\n\n    this.imageObj = new Image();\n\n    this.context = undefined;\n    this.message = undefined;\n    this.canvas = undefined;\n    this.rubberband_canvas = undefined;\n    this.rubberband_context = undefined;\n    this.format_dropdown = undefined;\n\n    this.image_mode = 'full';\n\n    this.root = document.createElement('div');\n    this.root.setAttribute('style', 'display: inline-block');\n    this._root_extra_style(this.root);\n\n    parent_element.appendChild(this.root);\n\n    this._init_header(this);\n    this._init_canvas(this);\n    this._init_toolbar(this);\n\n    var fig = this;\n\n    this.waiting = false;\n\n    this.ws.onopen = function () {\n        fig.send_message('supports_binary', { value: fig.supports_binary });\n        fig.send_message('send_image_mode', {});\n        if (fig.ratio !== 1) {\n            fig.send_message('set_device_pixel_ratio', {\n                device_pixel_ratio: fig.ratio,\n            });\n        }\n        fig.send_message('refresh', {});\n    };\n\n    this.imageObj.onload = function () {\n        if (fig.image_mode === 'full') {\n            // Full images could contain transparency (where diff images\n            // almost always do), so we need to clear the canvas so that\n            // there is no ghosting.\n            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n        }\n        fig.context.drawImage(fig.imageObj, 0, 0);\n    };\n\n    this.imageObj.onunload = function () {\n        fig.ws.close();\n    };\n\n    this.ws.onmessage = this._make_on_message_function(this);\n\n    this.ondownload = ondownload;\n};\n\nmpl.figure.prototype._init_header = function () {\n    var titlebar = document.createElement('div');\n    titlebar.classList =\n        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n    var titletext = document.createElement('div');\n    titletext.classList = 'ui-dialog-title';\n    titletext.setAttribute(\n        'style',\n        'width: 100%; text-align: center; padding: 3px;'\n    );\n    titlebar.appendChild(titletext);\n    this.root.appendChild(titlebar);\n    this.header = titletext;\n};\n\nmpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n\nmpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n\nmpl.figure.prototype._init_canvas = function () {\n    var fig = this;\n\n    var canvas_div = (this.canvas_div = document.createElement('div'));\n    canvas_div.setAttribute('tabindex', '0');\n    canvas_div.setAttribute(\n        'style',\n        'border: 1px solid #ddd;' +\n            'box-sizing: content-box;' +\n            'clear: both;' +\n            'min-height: 1px;' +\n            'min-width: 1px;' +\n            'outline: 0;' +\n            'overflow: hidden;' +\n            'position: relative;' +\n            'resize: both;' +\n            'z-index: 2;'\n    );\n\n    function on_keyboard_event_closure(name) {\n        return function (event) {\n            return fig.key_event(event, name);\n        };\n    }\n\n    canvas_div.addEventListener(\n        'keydown',\n        on_keyboard_event_closure('key_press')\n    );\n    canvas_div.addEventListener(\n        'keyup',\n        on_keyboard_event_closure('key_release')\n    );\n\n    this._canvas_extra_style(canvas_div);\n    this.root.appendChild(canvas_div);\n\n    var canvas = (this.canvas = document.createElement('canvas'));\n    canvas.classList.add('mpl-canvas');\n    canvas.setAttribute(\n        'style',\n        'box-sizing: content-box;' +\n            'pointer-events: none;' +\n            'position: relative;' +\n            'z-index: 0;'\n    );\n\n    this.context = canvas.getContext('2d');\n\n    var backingStore =\n        this.context.backingStorePixelRatio ||\n        this.context.webkitBackingStorePixelRatio ||\n        this.context.mozBackingStorePixelRatio ||\n        this.context.msBackingStorePixelRatio ||\n        this.context.oBackingStorePixelRatio ||\n        this.context.backingStorePixelRatio ||\n        1;\n\n    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n\n    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n        'canvas'\n    ));\n    rubberband_canvas.setAttribute(\n        'style',\n        'box-sizing: content-box;' +\n            'left: 0;' +\n            'pointer-events: none;' +\n            'position: absolute;' +\n            'top: 0;' +\n            'z-index: 1;'\n    );\n\n    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n    if (this.ResizeObserver === undefined) {\n        if (window.ResizeObserver !== undefined) {\n            this.ResizeObserver = window.ResizeObserver;\n        } else {\n            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n            this.ResizeObserver = obs.ResizeObserver;\n        }\n    }\n\n    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n        var nentries = entries.length;\n        for (var i = 0; i < nentries; i++) {\n            var entry = entries[i];\n            var width, height;\n            if (entry.contentBoxSize) {\n                if (entry.contentBoxSize instanceof Array) {\n                    // Chrome 84 implements new version of spec.\n                    width = entry.contentBoxSize[0].inlineSize;\n                    height = entry.contentBoxSize[0].blockSize;\n                } else {\n                    // Firefox implements old version of spec.\n                    width = entry.contentBoxSize.inlineSize;\n                    height = entry.contentBoxSize.blockSize;\n                }\n            } else {\n                // Chrome <84 implements even older version of spec.\n                width = entry.contentRect.width;\n                height = entry.contentRect.height;\n            }\n\n            // Keep the size of the canvas and rubber band canvas in sync with\n            // the canvas container.\n            if (entry.devicePixelContentBoxSize) {\n                // Chrome 84 implements new version of spec.\n                canvas.setAttribute(\n                    'width',\n                    entry.devicePixelContentBoxSize[0].inlineSize\n                );\n                canvas.setAttribute(\n                    'height',\n                    entry.devicePixelContentBoxSize[0].blockSize\n                );\n            } else {\n                canvas.setAttribute('width', width * fig.ratio);\n                canvas.setAttribute('height', height * fig.ratio);\n            }\n            /* This rescales the canvas back to display pixels, so that it\n             * appears correct on HiDPI screens. */\n            canvas.style.width = width + 'px';\n            canvas.style.height = height + 'px';\n\n            rubberband_canvas.setAttribute('width', width);\n            rubberband_canvas.setAttribute('height', height);\n\n            // And update the size in Python. We ignore the initial 0/0 size\n            // that occurs as the element is placed into the DOM, which should\n            // otherwise not happen due to the minimum size styling.\n            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n                fig.request_resize(width, height);\n            }\n        }\n    });\n    this.resizeObserverInstance.observe(canvas_div);\n\n    function on_mouse_event_closure(name) {\n        /* User Agent sniffing is bad, but WebKit is busted:\n         * https://bugs.webkit.org/show_bug.cgi?id=144526\n         * https://bugs.webkit.org/show_bug.cgi?id=181818\n         * The worst that happens here is that they get an extra browser\n         * selection when dragging, if this check fails to catch them.\n         */\n        var UA = navigator.userAgent;\n        var isWebKit = /AppleWebKit/.test(UA) && !/Chrome/.test(UA);\n        if(isWebKit) {\n            return function (event) {\n                /* This prevents the web browser from automatically changing to\n                 * the text insertion cursor when the button is pressed. We\n                 * want to control all of the cursor setting manually through\n                 * the 'cursor' event from matplotlib */\n                event.preventDefault()\n                return fig.mouse_event(event, name);\n            };\n        } else {\n            return function (event) {\n                return fig.mouse_event(event, name);\n            };\n        }\n    }\n\n    canvas_div.addEventListener(\n        'mousedown',\n        on_mouse_event_closure('button_press')\n    );\n    canvas_div.addEventListener(\n        'mouseup',\n        on_mouse_event_closure('button_release')\n    );\n    canvas_div.addEventListener(\n        'dblclick',\n        on_mouse_event_closure('dblclick')\n    );\n    // Throttle sequential mouse events to 1 every 20ms.\n    canvas_div.addEventListener(\n        'mousemove',\n        on_mouse_event_closure('motion_notify')\n    );\n\n    canvas_div.addEventListener(\n        'mouseenter',\n        on_mouse_event_closure('figure_enter')\n    );\n    canvas_div.addEventListener(\n        'mouseleave',\n        on_mouse_event_closure('figure_leave')\n    );\n\n    canvas_div.addEventListener('wheel', function (event) {\n        if (event.deltaY < 0) {\n            event.step = 1;\n        } else {\n            event.step = -1;\n        }\n        on_mouse_event_closure('scroll')(event);\n    });\n\n    canvas_div.appendChild(canvas);\n    canvas_div.appendChild(rubberband_canvas);\n\n    this.rubberband_context = rubberband_canvas.getContext('2d');\n    this.rubberband_context.strokeStyle = '#000000';\n\n    this._resize_canvas = function (width, height, forward) {\n        if (forward) {\n            canvas_div.style.width = width + 'px';\n            canvas_div.style.height = height + 'px';\n        }\n    };\n\n    // Disable right mouse context menu.\n    canvas_div.addEventListener('contextmenu', function (_e) {\n        event.preventDefault();\n        return false;\n    });\n\n    function set_focus() {\n        canvas.focus();\n        canvas_div.focus();\n    }\n\n    window.setTimeout(set_focus, 100);\n};\n\nmpl.figure.prototype._init_toolbar = function () {\n    var fig = this;\n\n    var toolbar = document.createElement('div');\n    toolbar.classList = 'mpl-toolbar';\n    this.root.appendChild(toolbar);\n\n    function on_click_closure(name) {\n        return function (_event) {\n            return fig.toolbar_button_onclick(name);\n        };\n    }\n\n    function on_mouseover_closure(tooltip) {\n        return function (event) {\n            if (!event.currentTarget.disabled) {\n                return fig.toolbar_button_onmouseover(tooltip);\n            }\n        };\n    }\n\n    fig.buttons = {};\n    var buttonGroup = document.createElement('div');\n    buttonGroup.classList = 'mpl-button-group';\n    for (var toolbar_ind in mpl.toolbar_items) {\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) {\n            /* Instead of a spacer, we start a new button group. */\n            if (buttonGroup.hasChildNodes()) {\n                toolbar.appendChild(buttonGroup);\n            }\n            buttonGroup = document.createElement('div');\n            buttonGroup.classList = 'mpl-button-group';\n            continue;\n        }\n\n        var button = (fig.buttons[name] = document.createElement('button'));\n        button.classList = 'mpl-widget';\n        button.setAttribute('role', 'button');\n        button.setAttribute('aria-disabled', 'false');\n        button.addEventListener('click', on_click_closure(method_name));\n        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n\n        var icon_img = document.createElement('img');\n        icon_img.src = '_images/' + image + '.png';\n        icon_img.srcset = '_images/' + image + '_large.png 2x';\n        icon_img.alt = tooltip;\n        button.appendChild(icon_img);\n\n        buttonGroup.appendChild(button);\n    }\n\n    if (buttonGroup.hasChildNodes()) {\n        toolbar.appendChild(buttonGroup);\n    }\n\n    var fmt_picker = document.createElement('select');\n    fmt_picker.classList = 'mpl-widget';\n    toolbar.appendChild(fmt_picker);\n    this.format_dropdown = fmt_picker;\n\n    for (var ind in mpl.extensions) {\n        var fmt = mpl.extensions[ind];\n        var option = document.createElement('option');\n        option.selected = fmt === mpl.default_extension;\n        option.innerHTML = fmt;\n        fmt_picker.appendChild(option);\n    }\n\n    var status_bar = document.createElement('span');\n    status_bar.classList = 'mpl-message';\n    toolbar.appendChild(status_bar);\n    this.message = status_bar;\n};\n\nmpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n    // which will in turn request a refresh of the image.\n    this.send_message('resize', { width: x_pixels, height: y_pixels });\n};\n\nmpl.figure.prototype.send_message = function (type, properties) {\n    properties['type'] = type;\n    properties['figure_id'] = this.id;\n    this.ws.send(JSON.stringify(properties));\n};\n\nmpl.figure.prototype.send_draw_message = function () {\n    if (!this.waiting) {\n        this.waiting = true;\n        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n    }\n};\n\nmpl.figure.prototype.handle_save = function (fig, _msg) {\n    var format_dropdown = fig.format_dropdown;\n    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n    fig.ondownload(fig, format);\n};\n\nmpl.figure.prototype.handle_resize = function (fig, msg) {\n    var size = msg['size'];\n    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n        fig._resize_canvas(size[0], size[1], msg['forward']);\n        fig.send_message('refresh', {});\n    }\n};\n\nmpl.figure.prototype.handle_rubberband = function (fig, msg) {\n    var x0 = msg['x0'] / fig.ratio;\n    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n    var x1 = msg['x1'] / fig.ratio;\n    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n    x0 = Math.floor(x0) + 0.5;\n    y0 = Math.floor(y0) + 0.5;\n    x1 = Math.floor(x1) + 0.5;\n    y1 = Math.floor(y1) + 0.5;\n    var min_x = Math.min(x0, x1);\n    var min_y = Math.min(y0, y1);\n    var width = Math.abs(x1 - x0);\n    var height = Math.abs(y1 - y0);\n\n    fig.rubberband_context.clearRect(\n        0,\n        0,\n        fig.canvas.width / fig.ratio,\n        fig.canvas.height / fig.ratio\n    );\n\n    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n};\n\nmpl.figure.prototype.handle_figure_label = function (fig, msg) {\n    // Updates the figure title.\n    fig.header.textContent = msg['label'];\n};\n\nmpl.figure.prototype.handle_cursor = function (fig, msg) {\n    fig.canvas_div.style.cursor = msg['cursor'];\n};\n\nmpl.figure.prototype.handle_message = function (fig, msg) {\n    fig.message.textContent = msg['message'];\n};\n\nmpl.figure.prototype.handle_draw = function (fig, _msg) {\n    // Request the server to send over a new figure.\n    fig.send_draw_message();\n};\n\nmpl.figure.prototype.handle_image_mode = function (fig, msg) {\n    fig.image_mode = msg['mode'];\n};\n\nmpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n    for (var key in msg) {\n        if (!(key in fig.buttons)) {\n            continue;\n        }\n        fig.buttons[key].disabled = !msg[key];\n        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n    }\n};\n\nmpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n    if (msg['mode'] === 'PAN') {\n        fig.buttons['Pan'].classList.add('active');\n        fig.buttons['Zoom'].classList.remove('active');\n    } else if (msg['mode'] === 'ZOOM') {\n        fig.buttons['Pan'].classList.remove('active');\n        fig.buttons['Zoom'].classList.add('active');\n    } else {\n        fig.buttons['Pan'].classList.remove('active');\n        fig.buttons['Zoom'].classList.remove('active');\n    }\n};\n\nmpl.figure.prototype.updated_canvas_event = function () {\n    // Called whenever the canvas gets updated.\n    this.send_message('ack', {});\n};\n\n// A function to construct a web socket function for onmessage handling.\n// Called in the figure constructor.\nmpl.figure.prototype._make_on_message_function = function (fig) {\n    return function socket_on_message(evt) {\n        if (evt.data instanceof Blob) {\n            var img = evt.data;\n            if (img.type !== 'image/png') {\n                /* FIXME: We get \"Resource interpreted as Image but\n                 * transferred with MIME type text/plain:\" errors on\n                 * Chrome.  But how to set the MIME type?  It doesn't seem\n                 * to be part of the websocket stream */\n                img.type = 'image/png';\n            }\n\n            /* Free the memory for the previous frames */\n            if (fig.imageObj.src) {\n                (window.URL || window.webkitURL).revokeObjectURL(\n                    fig.imageObj.src\n                );\n            }\n\n            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n                img\n            );\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        } else if (\n            typeof evt.data === 'string' &&\n            evt.data.slice(0, 21) === 'data:image/png;base64'\n        ) {\n            fig.imageObj.src = evt.data;\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        }\n\n        var msg = JSON.parse(evt.data);\n        var msg_type = msg['type'];\n\n        // Call the  \"handle_{type}\" callback, which takes\n        // the figure and JSON message as its only arguments.\n        try {\n            var callback = fig['handle_' + msg_type];\n        } catch (e) {\n            console.log(\n                \"No handler for the '\" + msg_type + \"' message type: \",\n                msg\n            );\n            return;\n        }\n\n        if (callback) {\n            try {\n                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n                callback(fig, msg);\n            } catch (e) {\n                console.log(\n                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n                    e,\n                    e.stack,\n                    msg\n                );\n            }\n        }\n    };\n};\n\nfunction getModifiers(event) {\n    var mods = [];\n    if (event.ctrlKey) {\n        mods.push('ctrl');\n    }\n    if (event.altKey) {\n        mods.push('alt');\n    }\n    if (event.shiftKey) {\n        mods.push('shift');\n    }\n    if (event.metaKey) {\n        mods.push('meta');\n    }\n    return mods;\n}\n\n/*\n * return a copy of an object with only non-object keys\n * we need this to avoid circular references\n * https://stackoverflow.com/a/24161582/3208463\n */\nfunction simpleKeys(original) {\n    return Object.keys(original).reduce(function (obj, key) {\n        if (typeof original[key] !== 'object') {\n            obj[key] = original[key];\n        }\n        return obj;\n    }, {});\n}\n\nmpl.figure.prototype.mouse_event = function (event, name) {\n    if (name === 'button_press') {\n        this.canvas.focus();\n        this.canvas_div.focus();\n    }\n\n    // from https://stackoverflow.com/q/1114465\n    var boundingRect = this.canvas.getBoundingClientRect();\n    var x = (event.clientX - boundingRect.left) * this.ratio;\n    var y = (event.clientY - boundingRect.top) * this.ratio;\n\n    this.send_message(name, {\n        x: x,\n        y: y,\n        button: event.button,\n        step: event.step,\n        modifiers: getModifiers(event),\n        guiEvent: simpleKeys(event),\n    });\n\n    return false;\n};\n\nmpl.figure.prototype._key_event_extra = function (_event, _name) {\n    // Handle any extra behaviour associated with a key event\n};\n\nmpl.figure.prototype.key_event = function (event, name) {\n    // Prevent repeat events\n    if (name === 'key_press') {\n        if (event.key === this._key) {\n            return;\n        } else {\n            this._key = event.key;\n        }\n    }\n    if (name === 'key_release') {\n        this._key = null;\n    }\n\n    var value = '';\n    if (event.ctrlKey && event.key !== 'Control') {\n        value += 'ctrl+';\n    }\n    else if (event.altKey && event.key !== 'Alt') {\n        value += 'alt+';\n    }\n    else if (event.shiftKey && event.key !== 'Shift') {\n        value += 'shift+';\n    }\n\n    value += 'k' + event.key;\n\n    this._key_event_extra(event, name);\n\n    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n    return false;\n};\n\nmpl.figure.prototype.toolbar_button_onclick = function (name) {\n    if (name === 'download') {\n        this.handle_save(this, null);\n    } else {\n        this.send_message('toolbar_button', { name: name });\n    }\n};\n\nmpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n    this.message.textContent = tooltip;\n};\n\n///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n// prettier-ignore\nvar _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\nmpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o\", \"download\"]];\n\nmpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\", \"webp\"];\n\nmpl.default_extension = \"png\";/* global mpl */\n\nvar comm_websocket_adapter = function (comm) {\n    // Create a \"websocket\"-like object which calls the given IPython comm\n    // object with the appropriate methods. Currently this is a non binary\n    // socket, so there is still some room for performance tuning.\n    var ws = {};\n\n    ws.binaryType = comm.kernel.ws.binaryType;\n    ws.readyState = comm.kernel.ws.readyState;\n    function updateReadyState(_event) {\n        if (comm.kernel.ws) {\n            ws.readyState = comm.kernel.ws.readyState;\n        } else {\n            ws.readyState = 3; // Closed state.\n        }\n    }\n    comm.kernel.ws.addEventListener('open', updateReadyState);\n    comm.kernel.ws.addEventListener('close', updateReadyState);\n    comm.kernel.ws.addEventListener('error', updateReadyState);\n\n    ws.close = function () {\n        comm.close();\n    };\n    ws.send = function (m) {\n        //console.log('sending', m);\n        comm.send(m);\n    };\n    // Register the callback with on_msg.\n    comm.on_msg(function (msg) {\n        //console.log('receiving', msg['content']['data'], msg);\n        var data = msg['content']['data'];\n        if (data['blob'] !== undefined) {\n            data = {\n                data: new Blob(msg['buffers'], { type: data['blob'] }),\n            };\n        }\n        // Pass the mpl event to the overridden (by mpl) onmessage function.\n        ws.onmessage(data);\n    });\n    return ws;\n};\n\nmpl.mpl_figure_comm = function (comm, msg) {\n    // This is the function which gets called when the mpl process\n    // starts-up an IPython Comm through the \"matplotlib\" channel.\n\n    var id = msg.content.data.id;\n    // Get hold of the div created by the display call when the Comm\n    // socket was opened in Python.\n    var element = document.getElementById(id);\n    var ws_proxy = comm_websocket_adapter(comm);\n\n    function ondownload(figure, _format) {\n        window.open(figure.canvas.toDataURL());\n    }\n\n    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n\n    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n    // web socket which is closed, not our websocket->open comm proxy.\n    ws_proxy.onopen();\n\n    fig.parent_element = element;\n    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n    if (!fig.cell_info) {\n        console.error('Failed to find cell for figure', id, fig);\n        return;\n    }\n    fig.cell_info[0].output_area.element.on(\n        'cleared',\n        { fig: fig },\n        fig._remove_fig_handler\n    );\n};\n\nmpl.figure.prototype.handle_close = function (fig, msg) {\n    var width = fig.canvas.width / fig.ratio;\n    fig.cell_info[0].output_area.element.off(\n        'cleared',\n        fig._remove_fig_handler\n    );\n    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n\n    // Update the output cell to use the data from the current canvas.\n    fig.push_to_output();\n    var dataURL = fig.canvas.toDataURL();\n    // Re-enable the keyboard manager in IPython - without this line, in FF,\n    // the notebook keyboard shortcuts fail.\n    IPython.keyboard_manager.enable();\n    fig.parent_element.innerHTML =\n        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n    fig.close_ws(fig, msg);\n};\n\nmpl.figure.prototype.close_ws = function (fig, msg) {\n    fig.send_message('closing', msg);\n    // fig.ws.close()\n};\n\nmpl.figure.prototype.push_to_output = function (_remove_interactive) {\n    // Turn the data on the canvas into data in the output cell.\n    var width = this.canvas.width / this.ratio;\n    var dataURL = this.canvas.toDataURL();\n    this.cell_info[1]['text/html'] =\n        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n};\n\nmpl.figure.prototype.updated_canvas_event = function () {\n    // Tell IPython that the notebook contents must change.\n    IPython.notebook.set_dirty(true);\n    this.send_message('ack', {});\n    var fig = this;\n    // Wait a second, then push the new image to the DOM so\n    // that it is saved nicely (might be nice to debounce this).\n    setTimeout(function () {\n        fig.push_to_output();\n    }, 1000);\n};\n\nmpl.figure.prototype._init_toolbar = function () {\n    var fig = this;\n\n    var toolbar = document.createElement('div');\n    toolbar.classList = 'btn-toolbar';\n    this.root.appendChild(toolbar);\n\n    function on_click_closure(name) {\n        return function (_event) {\n            return fig.toolbar_button_onclick(name);\n        };\n    }\n\n    function on_mouseover_closure(tooltip) {\n        return function (event) {\n            if (!event.currentTarget.disabled) {\n                return fig.toolbar_button_onmouseover(tooltip);\n            }\n        };\n    }\n\n    fig.buttons = {};\n    var buttonGroup = document.createElement('div');\n    buttonGroup.classList = 'btn-group';\n    var button;\n    for (var toolbar_ind in mpl.toolbar_items) {\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) {\n            /* Instead of a spacer, we start a new button group. */\n            if (buttonGroup.hasChildNodes()) {\n                toolbar.appendChild(buttonGroup);\n            }\n            buttonGroup = document.createElement('div');\n            buttonGroup.classList = 'btn-group';\n            continue;\n        }\n\n        button = fig.buttons[name] = document.createElement('button');\n        button.classList = 'btn btn-default';\n        button.href = '#';\n        button.title = name;\n        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n        button.addEventListener('click', on_click_closure(method_name));\n        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n        buttonGroup.appendChild(button);\n    }\n\n    if (buttonGroup.hasChildNodes()) {\n        toolbar.appendChild(buttonGroup);\n    }\n\n    // Add the status bar.\n    var status_bar = document.createElement('span');\n    status_bar.classList = 'mpl-message pull-right';\n    toolbar.appendChild(status_bar);\n    this.message = status_bar;\n\n    // Add the close button to the window.\n    var buttongrp = document.createElement('div');\n    buttongrp.classList = 'btn-group inline pull-right';\n    button = document.createElement('button');\n    button.classList = 'btn btn-mini btn-primary';\n    button.href = '#';\n    button.title = 'Stop Interaction';\n    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n    button.addEventListener('click', function (_evt) {\n        fig.handle_close(fig, {});\n    });\n    button.addEventListener(\n        'mouseover',\n        on_mouseover_closure('Stop Interaction')\n    );\n    buttongrp.appendChild(button);\n    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n};\n\nmpl.figure.prototype._remove_fig_handler = function (event) {\n    var fig = event.data.fig;\n    if (event.target !== this) {\n        // Ignore bubbled events from children.\n        return;\n    }\n    fig.close_ws(fig, {});\n};\n\nmpl.figure.prototype._root_extra_style = function (el) {\n    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n};\n\nmpl.figure.prototype._canvas_extra_style = function (el) {\n    // this is important to make the div 'focusable\n    el.setAttribute('tabindex', 0);\n    // reach out to IPython and tell the keyboard manager to turn it's self\n    // off when our div gets focus\n\n    // location in version 3\n    if (IPython.notebook.keyboard_manager) {\n        IPython.notebook.keyboard_manager.register_events(el);\n    } else {\n        // location in version 2\n        IPython.keyboard_manager.register_events(el);\n    }\n};\n\nmpl.figure.prototype._key_event_extra = function (event, _name) {\n    // Check for shift+enter\n    if (event.shiftKey && event.which === 13) {\n        this.canvas_div.blur();\n        // select the cell after this one\n        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n        IPython.notebook.select(index + 1);\n    }\n};\n\nmpl.figure.prototype.handle_save = function (fig, _msg) {\n    fig.ondownload(fig, null);\n};\n\nmpl.find_output_cell = function (html_output) {\n    // Return the cell and output element which can be found *uniquely* in the notebook.\n    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n    // IPython event is triggered only after the cells have been serialised, which for\n    // our purposes (turning an active figure into a static one), is too late.\n    var cells = IPython.notebook.get_cells();\n    var ncells = cells.length;\n    for (var i = 0; i < ncells; i++) {\n        var cell = cells[i];\n        if (cell.cell_type === 'code') {\n            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n                var data = cell.output_area.outputs[j];\n                if (data.data) {\n                    // IPython >= 3 moved mimebundle to data attribute of output\n                    data = data.data;\n                }\n                if (data['text/html'] === html_output) {\n                    return [cell, data, j];\n                }\n            }\n        }\n    }\n};\n\n// Register the function which deals with the matplotlib target/channel.\n// The kernel may be null if the page has been refreshed.\nif (IPython.notebook.kernel !== null) {\n    IPython.notebook.kernel.comm_manager.register_target(\n        'matplotlib',\n        mpl.mpl_figure_comm\n    );\n}\n",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div id='d9609834-cc0d-42da-86f4-dbadacfe10fc'></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/matplotlib/animation.py:892: UserWarning: Animation was deleted without rendering anything. This is most likely not intended. To prevent deletion, assign the Animation to a variable, e.g. `anim`, that exists until you output the Animation using `plt.show()` or `anim.save()`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.set_xlim(0, 10)\n",
        "ax.set_ylim(0, 10)\n",
        "\n",
        "point, = ax.plot([], [], 'ro')\n",
        "\n",
        "def update(frame):\n",
        "    point.set_data(frame, frame)\n",
        "    return point,\n",
        "\n",
        "ani = FuncAnimation(fig, update, frames=range(10), blit=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bi2bK1e3dBlZ",
        "outputId": "ab76c3ae-c3eb-4efc-f884-2e6606265977"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing: /content/drive/MyDrive/PRIM/dataset/inputs/alatn.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/alatn_preprocessed.csv\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/inputs/bnivh.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/bnivh_preprocessed.csv\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/inputs/edysv.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/edysv_preprocessed.csv\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/inputs/enekh.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/enekh_preprocessed.csv\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/inputs/giplk.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/giplk_preprocessed.csv\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/inputs/homwl.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/homwl_preprocessed.csv\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/inputs/ipohn.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/ipohn_preprocessed.csv\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/inputs/mdhln.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/mdhln_preprocessed.csv\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/inputs/mehxb.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/mehxb_preprocessed.csv\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/inputs/nrxwh.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/nrxwh_preprocessed.csv\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/inputs/nxbhc.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/nxbhc_preprocessed.csv\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/inputs/orsqi.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/orsqi_preprocessed.csv\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/inputs/pciqj.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/pciqj_preprocessed.csv\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/inputs/rtrwk.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/rtrwk_preprocessed.csv\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/inputs/szgdk.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/szgdk_preprocessed.csv\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/inputs/tbhzi.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/tbhzi_preprocessed.csv\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/inputs/ypkjg.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/ypkjg_preprocessed.csv\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/inputs/zidxm.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/zidxm_preprocessed.csv\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/inputs/zsvsn.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/zsvsn_preprocessed.csv\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/inputs/hjefd.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/hjefd_preprocessed.csv\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/inputs/hucjj.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/hucjj_preprocessed.csv\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/inputs/kbfjj.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/kbfjj_preprocessed.csv\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/inputs/odsnu.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/odsnu_preprocessed.csv\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/inputs/owagb.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/owagb_preprocessed.csv\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/inputs/rhyqk.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/rhyqk_preprocessed.csv\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/inputs/sckat.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/sckat_preprocessed.csv\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/inputs/xunmo.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/xunmo_preprocessed.csv\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/inputs/ygfdz.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/ygfdz_preprocessed.csv\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/inputs/zbzpb.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/zbzpb_preprocessed.csv\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/inputs/okfqy.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/okfqy_preprocessed.csv\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/inputs/wmrgi.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/wmrgi_preprocessed.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import preprocess\n",
        "# Define input and output directories\n",
        "input_folder = '/content/drive/MyDrive/PRIM/dataset/inputs'\n",
        "output_folder = '/content/drive/MyDrive/PRIM/dataset/inputs_preprocessed'\n",
        "\n",
        "# Ensure output folder exists\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Iterate over all XML files in the input folder\n",
        "for file_name in os.listdir(input_folder):\n",
        "    if file_name.endswith(\".xml\"):  # Process only XML files\n",
        "        input_xml_path = os.path.join(input_folder, file_name)\n",
        "\n",
        "        print(f\"Processing: {input_xml_path}\")\n",
        "\n",
        "        # Preprocess the file\n",
        "        tree = preprocess.load_xml(input_xml_path)\n",
        "        extracted_data = preprocess.extract_data_from_input(tree)\n",
        "        df = preprocess.data_to_dataframe(extracted_data)\n",
        "        df_interpolated = preprocess.interpolate_data_with_flag(df)\n",
        "\n",
        "        # Define output file path\n",
        "        output_csv_path = os.path.join(output_folder, file_name.replace(\".xml\", \"_preprocessed.csv\"))\n",
        "\n",
        "        # Save the preprocessed DataFrame\n",
        "        preprocess.save_data(df_interpolated, output_csv_path)\n",
        "\n",
        "        print(f\"Saved preprocessed file to: {output_csv_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLBMspIQibVC",
        "outputId": "0525cdea-299b-4126-bb6a-bd9e2122692a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/hjefd.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/hjefd_preprocessed.csv\n",
            "2\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/alatn.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/alatn_preprocessed.csv\n",
            "3\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/tbhzi.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/tbhzi_preprocessed.csv\n",
            "4\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/mdhln.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/mdhln_preprocessed.csv\n",
            "5\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/enekh.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/enekh_preprocessed.csv\n",
            "6\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/sckat.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/sckat_preprocessed.csv\n",
            "7\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/hucjj.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/hucjj_preprocessed.csv\n",
            "8\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/ipohn.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/ipohn_preprocessed.csv\n",
            "9\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/zsvsn.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/zsvsn_preprocessed.csv\n",
            "10\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/giplk.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/giplk_preprocessed.csv\n",
            "11\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/nxbhc.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/nxbhc_preprocessed.csv\n",
            "12\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/rtrwk.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/rtrwk_preprocessed.csv\n",
            "13\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/ygfdz.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/ygfdz_preprocessed.csv\n",
            "14\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/bnivh.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/bnivh_preprocessed.csv\n",
            "15\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/homwl.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/homwl_preprocessed.csv\n",
            "16\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/zidxm.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/zidxm_preprocessed.csv\n",
            "17\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/odsnu.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/odsnu_preprocessed.csv\n",
            "18\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/szgdk.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/szgdk_preprocessed.csv\n",
            "19\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/ypkjg.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/ypkjg_preprocessed.csv\n",
            "20\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/owagb.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/owagb_preprocessed.csv\n",
            "21\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/zbzpb.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/zbzpb_preprocessed.csv\n",
            "22\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/xunmo.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/xunmo_preprocessed.csv\n",
            "23\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/edysv.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/edysv_preprocessed.csv\n",
            "24\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/wmrgi.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/wmrgi_preprocessed.csv\n",
            "25\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/nrxwh.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/nrxwh_preprocessed.csv\n",
            "26\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/mehxb.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/mehxb_preprocessed.csv\n",
            "27\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/orsqi.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/orsqi_preprocessed.csv\n",
            "28\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/rhyqk.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/rhyqk_preprocessed.csv\n",
            "29\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/pciqj.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/pciqj_preprocessed.csv\n",
            "30\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/okfqy.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/okfqy_preprocessed.csv\n",
            "31\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/kbfjj.xml\n",
            "Saved preprocessed file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/kbfjj_preprocessed.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Define input and output directories\n",
        "input_folder = '/content/drive/MyDrive/PRIM/dataset/outputs'\n",
        "output_folder = '/content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train'\n",
        "\n",
        "# Ensure output folder exists\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Desired column order\n",
        "desired_columns = [\n",
        "    'frame', 'stroke', 'player 1', 'player 2',\n",
        "    'backhand', 'forehand', 'serve', 'ball pass',\n",
        "    'point', 'mistake', 'void serve'\n",
        "]\n",
        "\n",
        "# Iterate over all XML files in the input folder\n",
        "p = 0\n",
        "for file_name in os.listdir(input_folder):\n",
        "    if file_name.endswith(\".xml\"):  # Process only XML files\n",
        "        p += 1\n",
        "        print(p)\n",
        "        input_xml_path = os.path.join(input_folder, file_name)\n",
        "\n",
        "        print(f\"Processing: {input_xml_path}\")\n",
        "\n",
        "        # Preprocess the file\n",
        "        tree = preprocess.load_xml(input_xml_path)\n",
        "        extracted_data = preprocess.extract_data_from_output(tree)\n",
        "        df = preprocess.data_to_dataframe(extracted_data)\n",
        "        df['stroke'] = df['player 1'] + df['player 2']\n",
        "        df['void serve'] = df['let serve'] + df['void serve']\n",
        "        # Reorder columns\n",
        "        df = df[desired_columns]\n",
        "        n_before = 30  # Number of frames before each stroke\n",
        "        n_after = 30   # Number of frames after each stroke\n",
        "\n",
        "        # 1. Find indices of strokes\n",
        "        stroke_indices = df[df[\"stroke\"] == 1].index\n",
        "\n",
        "        # 2. Create a set of indices to keep\n",
        "        indices_to_keep = set()\n",
        "\n",
        "        for idx in stroke_indices:\n",
        "            # Add stroke frame\n",
        "            indices_to_keep.add(idx)\n",
        "            # Add context frames before and after the stroke\n",
        "            indices_to_keep.update(range(max(0, idx - n_before), idx))  # Before\n",
        "            indices_to_keep.update(range(idx + 1, min(len(df), idx + 1 + n_after)))  # After\n",
        "\n",
        "        # 3. Filter DataFrame and ensure no duplicates\n",
        "        indices_to_keep = sorted(indices_to_keep)  # Convert set to sorted list\n",
        "        reduced_df = df.iloc[indices_to_keep].drop_duplicates(subset=['frame']).reset_index(drop=True)\n",
        "\n",
        "        # Define output file path\n",
        "        output_csv_path = os.path.join(output_folder, file_name.replace(\".xml\", \"_preprocessed.csv\"))\n",
        "\n",
        "        # Save the preprocessed DataFrame\n",
        "        preprocess.save_data(reduced_df, output_csv_path)\n",
        "\n",
        "        print(f\"Saved preprocessed file to: {output_csv_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRENakxx77YH",
        "outputId": "98fa4961-ae2a-458f-f9a5-f85367a9422c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/hjefd.xml\n",
            "Reduced Output DataFrame shape: (1303, 11)\n",
            "Reduced Input DataFrame shape: (1303, 117)\n",
            "Saved preprocessed output file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/hjefd_preprocessed.csv\n",
            "Saved preprocessed input file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/hjefd_preprocessed.csv\n",
            "2\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/alatn.xml\n",
            "Reduced Output DataFrame shape: (6569, 11)\n",
            "Reduced Input DataFrame shape: (6569, 117)\n",
            "Saved preprocessed output file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/alatn_preprocessed.csv\n",
            "Saved preprocessed input file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/alatn_preprocessed.csv\n",
            "3\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/tbhzi.xml\n",
            "Reduced Output DataFrame shape: (2967, 11)\n",
            "Reduced Input DataFrame shape: (2967, 117)\n",
            "Saved preprocessed output file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/tbhzi_preprocessed.csv\n",
            "Saved preprocessed input file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/tbhzi_preprocessed.csv\n",
            "4\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/mdhln.xml\n",
            "Reduced Output DataFrame shape: (2277, 11)\n",
            "Reduced Input DataFrame shape: (2277, 117)\n",
            "Saved preprocessed output file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/mdhln_preprocessed.csv\n",
            "Saved preprocessed input file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/mdhln_preprocessed.csv\n",
            "5\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/enekh.xml\n",
            "Reduced Output DataFrame shape: (3390, 11)\n",
            "Reduced Input DataFrame shape: (3390, 117)\n",
            "Saved preprocessed output file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/enekh_preprocessed.csv\n",
            "Saved preprocessed input file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/enekh_preprocessed.csv\n",
            "6\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/sckat.xml\n",
            "Reduced Output DataFrame shape: (4963, 11)\n",
            "Reduced Input DataFrame shape: (4963, 117)\n",
            "Saved preprocessed output file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/sckat_preprocessed.csv\n",
            "Saved preprocessed input file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/sckat_preprocessed.csv\n",
            "7\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/hucjj.xml\n",
            "Reduced Output DataFrame shape: (3152, 11)\n",
            "Reduced Input DataFrame shape: (3152, 117)\n",
            "Saved preprocessed output file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/hucjj_preprocessed.csv\n",
            "Saved preprocessed input file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/hucjj_preprocessed.csv\n",
            "8\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/ipohn.xml\n",
            "Reduced Output DataFrame shape: (19937, 11)\n",
            "Reduced Input DataFrame shape: (19937, 117)\n",
            "Saved preprocessed output file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/ipohn_preprocessed.csv\n",
            "Saved preprocessed input file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/ipohn_preprocessed.csv\n",
            "9\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/zsvsn.xml\n",
            "Reduced Output DataFrame shape: (9873, 11)\n",
            "Reduced Input DataFrame shape: (9873, 117)\n",
            "Saved preprocessed output file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/zsvsn_preprocessed.csv\n",
            "Saved preprocessed input file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/zsvsn_preprocessed.csv\n",
            "10\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/giplk.xml\n",
            "Reduced Output DataFrame shape: (2856, 11)\n",
            "Reduced Input DataFrame shape: (2856, 117)\n",
            "Saved preprocessed output file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/giplk_preprocessed.csv\n",
            "Saved preprocessed input file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/giplk_preprocessed.csv\n",
            "11\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/nxbhc.xml\n",
            "Reduced Output DataFrame shape: (2451, 11)\n",
            "Reduced Input DataFrame shape: (2451, 117)\n",
            "Saved preprocessed output file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/nxbhc_preprocessed.csv\n",
            "Saved preprocessed input file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/nxbhc_preprocessed.csv\n",
            "12\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/rtrwk.xml\n",
            "Reduced Output DataFrame shape: (2376, 11)\n",
            "Reduced Input DataFrame shape: (2376, 117)\n",
            "Saved preprocessed output file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/rtrwk_preprocessed.csv\n",
            "Saved preprocessed input file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/rtrwk_preprocessed.csv\n",
            "13\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/ygfdz.xml\n",
            "Reduced Output DataFrame shape: (2558, 11)\n",
            "Reduced Input DataFrame shape: (2558, 117)\n",
            "Saved preprocessed output file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/ygfdz_preprocessed.csv\n",
            "Saved preprocessed input file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/ygfdz_preprocessed.csv\n",
            "14\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/bnivh.xml\n",
            "Reduced Output DataFrame shape: (7476, 11)\n",
            "Reduced Input DataFrame shape: (7476, 117)\n",
            "Saved preprocessed output file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/bnivh_preprocessed.csv\n",
            "Saved preprocessed input file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/bnivh_preprocessed.csv\n",
            "15\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/homwl.xml\n",
            "Reduced Output DataFrame shape: (7478, 11)\n",
            "Reduced Input DataFrame shape: (7478, 117)\n",
            "Saved preprocessed output file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/homwl_preprocessed.csv\n",
            "Saved preprocessed input file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/homwl_preprocessed.csv\n",
            "16\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/zidxm.xml\n",
            "Reduced Output DataFrame shape: (14042, 11)\n",
            "Reduced Input DataFrame shape: (14042, 117)\n",
            "Saved preprocessed output file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/zidxm_preprocessed.csv\n",
            "Saved preprocessed input file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/zidxm_preprocessed.csv\n",
            "17\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/odsnu.xml\n",
            "Reduced Output DataFrame shape: (14292, 11)\n",
            "Reduced Input DataFrame shape: (14292, 117)\n",
            "Saved preprocessed output file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/odsnu_preprocessed.csv\n",
            "Saved preprocessed input file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/odsnu_preprocessed.csv\n",
            "18\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/szgdk.xml\n",
            "Reduced Output DataFrame shape: (2709, 11)\n",
            "Reduced Input DataFrame shape: (2709, 117)\n",
            "Saved preprocessed output file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/szgdk_preprocessed.csv\n",
            "Saved preprocessed input file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/szgdk_preprocessed.csv\n",
            "19\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/ypkjg.xml\n",
            "Reduced Output DataFrame shape: (10875, 11)\n",
            "Reduced Input DataFrame shape: (10875, 117)\n",
            "Saved preprocessed output file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/ypkjg_preprocessed.csv\n",
            "Saved preprocessed input file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/ypkjg_preprocessed.csv\n",
            "20\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/owagb.xml\n",
            "Reduced Output DataFrame shape: (9754, 11)\n",
            "Reduced Input DataFrame shape: (9754, 117)\n",
            "Saved preprocessed output file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/owagb_preprocessed.csv\n",
            "Saved preprocessed input file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/owagb_preprocessed.csv\n",
            "21\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/zbzpb.xml\n",
            "Reduced Output DataFrame shape: (3133, 11)\n",
            "Reduced Input DataFrame shape: (3133, 117)\n",
            "Saved preprocessed output file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/zbzpb_preprocessed.csv\n",
            "Saved preprocessed input file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/zbzpb_preprocessed.csv\n",
            "22\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/xunmo.xml\n",
            "Reduced Output DataFrame shape: (16125, 11)\n",
            "Reduced Input DataFrame shape: (16125, 117)\n",
            "Saved preprocessed output file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/xunmo_preprocessed.csv\n",
            "Saved preprocessed input file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/xunmo_preprocessed.csv\n",
            "23\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/edysv.xml\n",
            "Reduced Output DataFrame shape: (7395, 11)\n",
            "Reduced Input DataFrame shape: (7395, 117)\n",
            "Saved preprocessed output file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/edysv_preprocessed.csv\n",
            "Saved preprocessed input file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/edysv_preprocessed.csv\n",
            "24\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/wmrgi.xml\n",
            "Reduced Output DataFrame shape: (15125, 11)\n",
            "Reduced Input DataFrame shape: (15125, 117)\n",
            "Saved preprocessed output file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/wmrgi_preprocessed.csv\n",
            "Saved preprocessed input file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/wmrgi_preprocessed.csv\n",
            "25\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/nrxwh.xml\n",
            "Reduced Output DataFrame shape: (9314, 11)\n",
            "Reduced Input DataFrame shape: (9314, 117)\n",
            "Saved preprocessed output file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/nrxwh_preprocessed.csv\n",
            "Saved preprocessed input file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/nrxwh_preprocessed.csv\n",
            "26\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/mehxb.xml\n",
            "Reduced Output DataFrame shape: (4774, 11)\n",
            "Reduced Input DataFrame shape: (4774, 117)\n",
            "Saved preprocessed output file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/mehxb_preprocessed.csv\n",
            "Saved preprocessed input file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/mehxb_preprocessed.csv\n",
            "27\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/orsqi.xml\n",
            "Reduced Output DataFrame shape: (7286, 11)\n",
            "Reduced Input DataFrame shape: (7286, 117)\n",
            "Saved preprocessed output file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/orsqi_preprocessed.csv\n",
            "Saved preprocessed input file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/orsqi_preprocessed.csv\n",
            "28\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/rhyqk.xml\n",
            "Reduced Output DataFrame shape: (15785, 11)\n",
            "Reduced Input DataFrame shape: (15785, 117)\n",
            "Saved preprocessed output file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/rhyqk_preprocessed.csv\n",
            "Saved preprocessed input file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/rhyqk_preprocessed.csv\n",
            "29\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/pciqj.xml\n",
            "Reduced Output DataFrame shape: (6585, 11)\n",
            "Reduced Input DataFrame shape: (6585, 117)\n",
            "Saved preprocessed output file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/pciqj_preprocessed.csv\n",
            "Saved preprocessed input file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/pciqj_preprocessed.csv\n",
            "30\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/okfqy.xml\n",
            "Reduced Output DataFrame shape: (8353, 11)\n",
            "Reduced Input DataFrame shape: (8353, 117)\n",
            "Saved preprocessed output file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/okfqy_preprocessed.csv\n",
            "Saved preprocessed input file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/okfqy_preprocessed.csv\n",
            "31\n",
            "Processing: /content/drive/MyDrive/PRIM/dataset/outputs/kbfjj.xml\n",
            "Reduced Output DataFrame shape: (3442, 11)\n",
            "Reduced Input DataFrame shape: (3442, 117)\n",
            "Saved preprocessed output file to: /content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train/kbfjj_preprocessed.csv\n",
            "Saved preprocessed input file to: /content/drive/MyDrive/PRIM/dataset/inputs_preprocessed/kbfjj_preprocessed.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Define input and output directories\n",
        "input_folder = '/content/drive/MyDrive/PRIM/dataset/outputs'\n",
        "output_folder = '/content/drive/MyDrive/PRIM/dataset/outputs_preprocessed_train'\n",
        "input_preprocessed_folder = '/content/drive/MyDrive/PRIM/dataset/inputs_preprocessed'\n",
        "\n",
        "# Ensure output folders exist\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "os.makedirs(input_preprocessed_folder, exist_ok=True)\n",
        "\n",
        "# Desired column order\n",
        "desired_columns = [\n",
        "    'frame', 'stroke', 'player 1', 'player 2',\n",
        "    'backhand', 'forehand', 'serve', 'ball pass',\n",
        "    'point', 'mistake', 'void serve'\n",
        "]\n",
        "\n",
        "# Function to normalize the input data\n",
        "def normalize_data(df, method=\"standard\"):\n",
        "    \"\"\"\n",
        "    Normalize the input DataFrame.\n",
        "\n",
        "    Args:\n",
        "    - df (pd.DataFrame): Input DataFrame to normalize.\n",
        "    - method (str): Normalization method ('standard' or 'minmax').\n",
        "\n",
        "    Returns:\n",
        "    - pd.DataFrame: Normalized DataFrame.\n",
        "    \"\"\"\n",
        "    if method == \"standard\":\n",
        "        # Standard scaling: (x - mean) / std\n",
        "        return (df - df.mean()) / df.std()\n",
        "    elif method == \"minmax\":\n",
        "        # Min-max scaling: (x - min) / (max - min)\n",
        "        return (df - df.min()) / (df.max() - df.min())\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported normalization method. Use 'standard' or 'minmax'.\")\n",
        "\n",
        "# Main preprocessing loop\n",
        "p = 0\n",
        "for file_name in os.listdir(input_folder):\n",
        "    if file_name.endswith(\".xml\"):  # Process only XML files\n",
        "        p += 1\n",
        "        print(p)\n",
        "        input_xml_path = os.path.join(input_folder, file_name)\n",
        "        input_csv_path = os.path.join('/content/drive/MyDrive/PRIM/dataset/inputs_preprocessed', file_name.replace(\".xml\", \"_preprocessed.csv\"))\n",
        "\n",
        "        print(f\"Processing: {input_xml_path}\")\n",
        "\n",
        "        # Preprocess the file (Output Data)\n",
        "        tree = preprocess.load_xml(input_xml_path)\n",
        "        extracted_data = preprocess.extract_data_from_output(tree)\n",
        "        df_output = preprocess.data_to_dataframe(extracted_data)\n",
        "        df_output['stroke'] = df_output['player 1'] + df_output['player 2']\n",
        "        df_output['void serve'] = df_output['let serve'] + df_output['void serve']\n",
        "        # Reorder columns\n",
        "        df_output = df_output[desired_columns]\n",
        "\n",
        "        # Preprocess the Input Data\n",
        "        df_input = pd.read_csv(input_csv_path)  # Load corresponding input data\n",
        "\n",
        "        n_before = 30  # Number of frames before each stroke\n",
        "        n_after = 30   # Number of frames after each stroke\n",
        "\n",
        "        # 1. Find indices of strokes\n",
        "        stroke_indices = df_output[df_output[\"stroke\"] == 1].index\n",
        "\n",
        "        # 2. Create a set of indices to keep\n",
        "        indices_to_keep = set()\n",
        "\n",
        "        for idx in stroke_indices:\n",
        "            # Add stroke frame\n",
        "            indices_to_keep.add(idx)\n",
        "            # Add context frames before and after the stroke\n",
        "            indices_to_keep.update(range(max(0, idx - n_before), idx))  # Before\n",
        "            indices_to_keep.update(range(idx + 1, min(len(df_output), idx + 1 + n_after)))  # After\n",
        "\n",
        "        # 3. Filter Output and Input DataFrames\n",
        "        indices_to_keep = sorted(indices_to_keep)  # Convert set to sorted list\n",
        "        reduced_df_output = df_output.iloc[indices_to_keep].drop_duplicates(subset=['frame']).reset_index(drop=True)\n",
        "        reduced_df_input = df_input.iloc[indices_to_keep].reset_index(drop=True)\n",
        "\n",
        "        # Normalize Input Data\n",
        "        columns_to_normalize = [col for col in reduced_df_input.columns if col != \"frame\"]\n",
        "\n",
        "        # Normalize only selected columns\n",
        "        reduced_df_input[columns_to_normalize] = normalize_data(reduced_df_input[columns_to_normalize], method=\"standard\")\n",
        "\n",
        "        print(f\"Reduced Output DataFrame shape: {reduced_df_output.shape}\")\n",
        "        print(f\"Reduced Input DataFrame shape: {reduced_df_input.shape}\")\n",
        "\n",
        "        # Define output file paths\n",
        "        output_csv_path = os.path.join(output_folder, file_name.replace(\".xml\", \"_preprocessed.csv\"))\n",
        "        input_preprocessed_csv_path = os.path.join(input_preprocessed_folder, file_name.replace(\".xml\", \"_preprocessed.csv\"))\n",
        "\n",
        "        # Save the preprocessed DataFrames\n",
        "        preprocess.save_data(reduced_df_output, output_csv_path)\n",
        "        reduced_df_input.to_csv(input_preprocessed_csv_path, index=False)\n",
        "\n",
        "        print(f\"Saved preprocessed output file to: {output_csv_path}\")\n",
        "        print(f\"Saved preprocessed input file to: {input_preprocessed_csv_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gjMoPvSc1pgX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class TimeSeriesDataset(Dataset):\n",
        "    def __init__(self, feature_files, target_files, chunk_length, overlap):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            feature_files (list): List of file paths to CSV files containing feature columns.\n",
        "            target_files (list): List of file paths to CSV files containing target columns (one-to-one correspondence with feature_files).\n",
        "            chunk_length (int): Length of each chunk.\n",
        "            overlap (int): Overlap between consecutive chunks.\n",
        "        \"\"\"\n",
        "        assert len(feature_files) == len(target_files), \"Feature files and target files must match in number.\"\n",
        "        self.chunk_length = chunk_length\n",
        "        self.overlap = overlap\n",
        "        # Pair feature and target files\n",
        "        self.file_pairs = list(zip(feature_files, target_files))\n",
        "        # Process all file pairs to generate chunks\n",
        "        self.chunks = self._process_all_file_pairs()\n",
        "\n",
        "    def _process_all_file_pairs(self):\n",
        "        all_chunks = []\n",
        "        for feature_file, target_file in self.file_pairs:\n",
        "            feature_df = pd.read_csv(feature_file)\n",
        "            target_df = pd.read_csv(target_file)\n",
        "            # Drop the first column if it's an index\n",
        "            feature_df.drop(feature_df.columns[0], axis=1, inplace=True)\n",
        "            target_df.drop(target_df.columns[0], axis=1, inplace=True)\n",
        "            # Create chunks and local row-to-chunks mapping\n",
        "            chunks = self._create_chunks(feature_df, target_df)\n",
        "            all_chunks.extend(chunks)\n",
        "        return all_chunks\n",
        "\n",
        "    def _create_chunks(self, feature_df, target_df):\n",
        "        \"\"\"\n",
        "        Split data into overlapping chunks and track overlap contributions.\n",
        "        \"\"\"\n",
        "        step = self.chunk_length - self.overlap\n",
        "        num_chunks = (len(feature_df) - self.overlap) // step + 1\n",
        "        chunks = []\n",
        "\n",
        "        for i in range(num_chunks):\n",
        "            start = i * step\n",
        "            end = start + self.chunk_length\n",
        "            chunk_features = feature_df.iloc[start:end]\n",
        "            chunk_targets = target_df.iloc[start:end]\n",
        "\n",
        "            if len(chunk_features) < self.chunk_length:\n",
        "                # Pad features and targets to the required length\n",
        "                padding_rows = self.chunk_length - len(chunk_features)\n",
        "                feature_padding = pd.DataFrame(\n",
        "                    np.repeat([[0] * feature_df.shape[1]], padding_rows, axis=0),\n",
        "                    columns=feature_df.columns,\n",
        "                )\n",
        "                target_padding = pd.DataFrame(\n",
        "                    np.repeat([[-1] * target_df.shape[1]], padding_rows, axis=0),\n",
        "                    columns=target_df.columns,\n",
        "                )\n",
        "\n",
        "                chunk_features = pd.concat([chunk_features, feature_padding], ignore_index=True)\n",
        "                chunk_targets = pd.concat([chunk_targets, target_padding], ignore_index=True)\n",
        "\n",
        "            features = chunk_features.values\n",
        "            targets = chunk_targets.values\n",
        "            chunks.append((features, targets))\n",
        "\n",
        "        return chunks\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.chunks)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        features, targets = self.chunks[idx]\n",
        "        features = torch.tensor(features, dtype=torch.float32)\n",
        "        targets = torch.tensor(targets, dtype=torch.float32)\n",
        "        return features, targets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cWdujbqV9Le8"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "def calculate_file_lengths(feature_files):\n",
        "    \"\"\"\n",
        "    Calculate the number of rows in each feature file.\n",
        "    Args:\n",
        "        feature_files: List of file paths to feature CSVs.\n",
        "    Returns:\n",
        "        List of lengths corresponding to each file.\n",
        "    \"\"\"\n",
        "    file_lengths = []\n",
        "    for file in feature_files:\n",
        "        df = pd.read_csv(file)\n",
        "        file_lengths.append(len(df))\n",
        "    return file_lengths\n",
        "def proportional_split(feature_files, target_files, file_lengths, train_ratio=0.7, val_ratio=0.2, test_ratio=0.1):\n",
        "    \"\"\"\n",
        "    Split files proportionally by their lengths into train, validation, and test sets.\n",
        "    Args:\n",
        "        feature_files: List of feature file paths.\n",
        "        target_files: List of target file paths.\n",
        "        file_lengths: List of file lengths (row counts).\n",
        "        train_ratio: Proportion of data for training.\n",
        "        val_ratio: Proportion of data for validation.\n",
        "        test_ratio: Proportion of data for testing.\n",
        "    Returns:\n",
        "        Tuple: (train_features, train_targets, val_features, val_targets, test_features, test_targets)\n",
        "    \"\"\"\n",
        "    assert len(feature_files) == len(target_files) == len(file_lengths), \"Mismatch in file lists and lengths.\"\n",
        "    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-6, \"Ratios must sum to 1.\"\n",
        "\n",
        "    total_rows = sum(file_lengths)\n",
        "\n",
        "    train_threshold = total_rows * train_ratio\n",
        "    val_threshold = total_rows * (train_ratio + val_ratio)\n",
        "\n",
        "    # Split files\n",
        "    train_features, val_features, test_features = [], [], []\n",
        "    train_targets, val_targets, test_targets = [], [], []\n",
        "    cumulative_rows = 0\n",
        "\n",
        "    for i, length in enumerate(file_lengths):\n",
        "        cumulative_rows += length\n",
        "\n",
        "        if cumulative_rows <= train_threshold:\n",
        "            train_features.append(feature_files[i])\n",
        "            train_targets.append(target_files[i])\n",
        "        elif cumulative_rows <= val_threshold:\n",
        "            val_features.append(feature_files[i])\n",
        "            val_targets.append(target_files[i])\n",
        "        else:\n",
        "            test_features.append(feature_files[i])\n",
        "            test_targets.append(target_files[i])\n",
        "\n",
        "    return train_features, train_targets, val_features, val_targets, test_features, test_targets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Y4uq4owp2E0",
        "outputId": "6d7cb205-8319-4cb6-df07-e01407ee0bfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "195\n",
            "19844\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/PRIM/dataset/outputs_preprocessed/alatn_preprocessed.csv\")\n",
        "print((df[\"stroke\"] == 1).sum())\n",
        "print((df[\"stroke\"] == 0).sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RX4ZNj7EsxJB",
        "outputId": "0845f2f0-1192-4c11-a8c3-066fea399ae9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean frames between strokes: 94.89690721649484\n",
            "Median frames between strokes: 25.0\n",
            "Minimum frames between strokes: 9.0\n",
            "Maximum frames between strokes: 2478.0\n",
            "Standard deviation: 215.71817560354506\n",
            "\n",
            "All frame differences:\n",
            "1280      17.0\n",
            "1305      25.0\n",
            "1562     257.0\n",
            "1588      26.0\n",
            "1610      22.0\n",
            "         ...  \n",
            "19448     92.0\n",
            "19611    163.0\n",
            "19634     23.0\n",
            "19663     29.0\n",
            "19673     10.0\n",
            "Name: frame, Length: 194, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Filter rows where stroke == 1\n",
        "stroke_frames = df[df[\"stroke\"] == 1][\"frame\"]\n",
        "\n",
        "# Calculate differences between consecutive strokes\n",
        "frame_differences = stroke_frames.diff().dropna()  # Use .dropna() to remove the first NaN\n",
        "\n",
        "# Summary statistics\n",
        "print(\"Mean frames between strokes:\", frame_differences.mean())\n",
        "print(\"Median frames between strokes:\", frame_differences.median())\n",
        "print(\"Minimum frames between strokes:\", frame_differences.min())\n",
        "print(\"Maximum frames between strokes:\", frame_differences.max())\n",
        "print(\"Standard deviation:\", frame_differences.std())\n",
        "\n",
        "# Optionally, view all differences\n",
        "print(\"\\nAll frame differences:\")\n",
        "print(frame_differences)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "XZl-G4jMvapI",
        "outputId": "3b271c1e-fe0f-415a-9012-af1e0893edfe"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3398746efc15>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dataset:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stroke\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mn_before\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m  \u001b[0;31m# Number of frames before each stroke\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mn_after\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m   \u001b[0;31m# Number of frames after each stroke\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ],
      "source": [
        "print(\"dataset:\", (df[\"stroke\"] == 1).sum())\n",
        "\n",
        "n_before = 30  # Number of frames before each stroke\n",
        "n_after = 30   # Number of frames after each stroke\n",
        "\n",
        "# 1. Find indices of strokes\n",
        "stroke_indices = df[df[\"stroke\"] == 1].index\n",
        "\n",
        "# 2. Create a set of indices to keep\n",
        "indices_to_keep = set()\n",
        "\n",
        "for idx in stroke_indices:\n",
        "    # Add stroke frame\n",
        "    indices_to_keep.add(idx)\n",
        "    # Add context frames before and after the stroke\n",
        "    indices_to_keep.update(range(max(0, idx - n_before), idx))  # Before\n",
        "    indices_to_keep.update(range(idx + 1, min(len(df), idx + 1 + n_after)))  # After\n",
        "\n",
        "# 3. Filter DataFrame and ensure no duplicates\n",
        "indices_to_keep = sorted(indices_to_keep)  # Convert set to sorted list\n",
        "reduced_df = df.iloc[indices_to_keep].drop_duplicates(subset=['frame']).reset_index(drop=True)\n",
        "\n",
        "# 4. Save the reduced dataset if needed\n",
        "reduced_df.to_csv(\"reduced_dataset_with_context.csv\", index=False)\n",
        "\n",
        "# Print summary\n",
        "print(\"Original dataset size:\", len(df))\n",
        "print(\"Reduced dataset size:\", len(reduced_df))\n",
        "print(\"Number of strokes in reduced dataset:\", (reduced_df[\"stroke\"] == 1).sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYgqEBeeDk40",
        "outputId": "970b515e-9f83-4d21-90b8-fe3df621ecd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File lengths: [6569, 7476, 7395, 3390, 2856, 1303, 7478, 3152, 19937, 3442, 2277, 4774, 9314, 2451, 14292, 8353, 7286, 9754, 6585, 15785, 2376, 4963, 2709, 2967, 15125, 16125, 2558, 10875, 3133, 14042, 9873]\n",
            "Train: 4 files\n",
            "Train: 24830 files\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "# IndependentVideoDataset remains unchanged\n",
        "\n",
        "# Directories for features and targets\n",
        "feature_dir = r\"C:\\Users\\ASUS\\Desktop\\PRIM\\data\\dataset\\dataset\\inputs\\inputs_preprocessed\\inputs_preprocessed\"\n",
        "target_dir = r\"C:\\Users\\ASUS\\Desktop\\PRIM\\data\\dataset\\dataset\\outputs\\outputs_preprocessed_train\\outputs_preprocessed_train\"\n",
        "\n",
        "# Get full paths to feature files and target files\n",
        "feature_files = [\n",
        "    os.path.join(feature_dir, f) for f in os.listdir(feature_dir)\n",
        "    if os.path.isfile(os.path.join(feature_dir, f))\n",
        "]\n",
        "\n",
        "target_files = [\n",
        "    os.path.join(target_dir, f) for f in os.listdir(target_dir)\n",
        "    if os.path.isfile(os.path.join(target_dir, f))\n",
        "]\n",
        "\n",
        "# Ensure feature_files and target_files are sorted for one-to-one correspondence\n",
        "feature_files.sort()\n",
        "target_files.sort()\n",
        "\n",
        "\n",
        "# Dataset and DataLoader parameters\n",
        "chunk_length = 128\n",
        "overlap = 112\n",
        "\n",
        "\n",
        "# Calculate lengths of each file\n",
        "file_lengths = calculate_file_lengths(feature_files)\n",
        "\n",
        "train_features = feature_files[:4]\n",
        "train_targets = target_files[:4]\n",
        "print(f\"File lengths: {file_lengths}\")\n",
        "# Proportionally split files into train, val, and test sets\n",
        "\"\"\"\n",
        "train_features, train_targets, val_features, val_targets, test_features, test_targets = proportional_split(\n",
        "    feature_files, target_files, file_lengths, train_ratio=0.7, val_ratio=0.2, test_ratio=0.1\n",
        ")\n",
        "\n",
        "print(f\"Train: {len(train_features)} files, Val: {len(val_features)} files, Test: {len(test_features)} files\")\n",
        "print(f\"Train: {sum(file_lengths[:len(train_features)])} files, Val: {sum(file_lengths[len(train_features):len(train_features)+len(val_features)])} files, Test: {sum(file_lengths[len(train_features)+len(val_features):])} files\")\n",
        "\"\"\"\n",
        "print(f\"Train: {len(train_features)} files\")\n",
        "print(f\"Train: {sum(file_lengths[:len(train_features)])} files\")\n",
        "train_dataset = TimeSeriesDataset(train_features, train_targets, chunk_length=chunk_length, overlap=0)\n",
        "#val_dataset = TimeSeriesDataset(val_features, val_targets, chunk_length=chunk_length, overlap=overlap)\n",
        "#test_dataset = TimeSeriesDataset(test_features, test_targets, chunk_length=chunk_length, overlap=overlap)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=False)\n",
        "#val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
        "#test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYtXdbhBPhhg",
        "outputId": "fd9ac157-0561-4553-8825-33f09bf2df43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch length: 2\n",
            "Features shape: torch.Size([16, 128, 116])\n",
            "Targets shape: torch.Size([16, 128, 10])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for batch in train_dataloader:\n",
        "    print(f\"Batch length: {len(batch)}\")  # How many elements are in the batch?\n",
        "    print(f\"Features shape: {batch[0].shape}\")  # Features (first element)\n",
        "    print(f\"Targets shape: {batch[1].shape}\")  # Targets (second element)\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yk54cwUitwN_"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# Loss Function\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "L-GvmN9WFNaT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "def loss_in(y_pred, y_true, alpha=(1.0, 1.0, 1.0, 1.0, 1.0)):\n",
        "    \"\"\"\n",
        "    y_pred : tuple of predictions (logits)\n",
        "    y_true : tuple of ground truth labels\n",
        "    \"\"\"\n",
        "    y_pred_stroke, y_pred_player, y_pred_type, y_pred_role, y_pred_impact = y_pred\n",
        "    y_true_stroke = y_true[:, :, 0].unsqueeze(-1)\n",
        "    y_true_player = y_true[:, :, 1:3]\n",
        "    y_true_type = y_true[:, :, 3:5]\n",
        "    y_true_role = torch.stack([y_true[:, :, 5], y_true[:, :, 6], y_true[:, :, 5] + y_true[:, :, 6]], dim=-1)\n",
        "    y_true_impact = torch.cat([y_true[:, :, 7:], torch.sum(y_true[:, :, 7:], dim=-1, keepdim=True)], dim=-1)\n",
        "\n",
        "    # Mask for valid stroke labels\n",
        "    mask_stroke = (y_true_stroke != -1).squeeze(-1)\n",
        "\n",
        "    # Weight for balancing positive and negative examples\n",
        "    weight = torch.ones_like(y_true_stroke)\n",
        "    weight[y_true_stroke == 1] = 30\n",
        "    weight = weight[mask_stroke]\n",
        "\n",
        "    # Compute weighted BCEWithLogitsLoss\n",
        "    bce_with_logits_loss = nn.BCEWithLogitsLoss(weight=weight)\n",
        "    loss_stroke = bce_with_logits_loss(y_pred_stroke[mask_stroke], y_true_stroke[mask_stroke]) if mask_stroke.sum() > 0 else 0.0\n",
        "\n",
        "    # Mask for valid player, type, role, and impact predictions (only for positive strokes)\n",
        "    mask = (y_true_stroke == 1).squeeze(-1)\n",
        "\n",
        "    # Other losses (computed only for valid strokes)\n",
        "    loss_player = F.cross_entropy(\n",
        "        y_pred_player[mask], y_true_player[mask]\n",
        "    ) if mask.sum() > 0 else 0.0\n",
        "\n",
        "    loss_type = F.cross_entropy(\n",
        "        y_pred_type[mask], y_true_type[mask]\n",
        "    ) if mask.sum() > 0 else 0.0\n",
        "\n",
        "    loss_role = F.cross_entropy(\n",
        "        y_pred_role[mask], y_true_role[mask]\n",
        "    ) if mask.sum() > 0 else 0.0\n",
        "\n",
        "    loss_impact = F.cross_entropy(\n",
        "        y_pred_impact[mask], y_true_impact[mask]\n",
        "    ) if mask.sum() > 0 else 0.0\n",
        "\n",
        "    # Total loss with alpha weighting\n",
        "    total_loss = (\n",
        "        alpha[0] * loss_stroke +\n",
        "        alpha[1] * loss_player +\n",
        "        alpha[2] * loss_type +\n",
        "        alpha[3] * loss_role +\n",
        "        alpha[4] * loss_impact\n",
        "    )\n",
        "\n",
        "    return total_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "mBziNKWHx2de"
      },
      "outputs": [],
      "source": [
        "def loss(y_pred, y_true, log_vars):\n",
        "    # Unpack predictions\n",
        "    y_pred_stroke, y_pred_player, y_pred_type, y_pred_role, y_pred_impact = y_pred\n",
        "    y_true_stroke = y_true[:, :, 0].unsqueeze(-1)\n",
        "    y_true_player = y_true[:, :, 1:3]\n",
        "    y_true_type = y_true[:, :, 3:5]\n",
        "    y_true_role = torch.stack([y_true[:, :, 5], y_true[:, :, 6], y_true[:, :, 5] + y_true[:, :, 6]], dim=-1)\n",
        "    y_true_impact = torch.cat([y_true[:, :, 7:], torch.sum(y_true[:, :, 7:], dim=-1, keepdim=True)], dim=-1)\n",
        "\n",
        "    # Task-specific loss computation\n",
        "    mask_stroke = (y_true_stroke != -1).squeeze(-1)\n",
        "    weight = torch.ones_like(y_true_stroke)\n",
        "    weight[y_true_stroke == 1] = 30\n",
        "    weight = weight[mask_stroke]\n",
        "\n",
        "    bce_with_logits_loss = nn.BCEWithLogitsLoss(weight=weight)\n",
        "    loss_stroke = bce_with_logits_loss(y_pred_stroke[mask_stroke], y_true_stroke[mask_stroke]) if mask_stroke.sum() > 0 else 0.0\n",
        "\n",
        "    mask = (y_true_stroke == 1).squeeze(-1)\n",
        "    loss_player = F.cross_entropy(y_pred_player[mask], y_true_player[mask]) if mask.sum() > 0 else 0.0\n",
        "    loss_type = F.cross_entropy(y_pred_type[mask], y_true_type[mask]) if mask.sum() > 0 else 0.0\n",
        "    loss_role = F.cross_entropy(y_pred_role[mask], y_true_role[mask]) if mask.sum() > 0 else 0.0\n",
        "    loss_impact = F.cross_entropy(y_pred_impact[mask], y_true_impact[mask]) if mask.sum() > 0 else 0.0\n",
        "\n",
        "\n",
        "    # Total loss using learnable log variances\n",
        "    # Total loss using learnable log variances\n",
        "    total_loss = (\n",
        "        (1 / (2 * torch.exp(log_vars[0]))) * loss_stroke + log_vars[0] +\n",
        "        (1 / (2 * torch.exp(log_vars[1]))) * loss_player + log_vars[1] +\n",
        "        (1 / (2 * torch.exp(log_vars[2]))) * loss_type + log_vars[2] +\n",
        "        (1 / (2 * torch.exp(log_vars[3]))) * loss_role + log_vars[3] +\n",
        "        (1 / (2 * torch.exp(log_vars[4]))) * loss_impact + log_vars[4]\n",
        "    )\n",
        "\n",
        "\n",
        "    return total_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "jgNXy3eFyNzB"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "class FixedPositionalEncoding(nn.Module):\n",
        "    \"\"\"Inject some information about the relative or absolute position of the tokens\n",
        "        in the sequence. The positional encodings have the same dimension as\n",
        "        the embeddings, so that the two can be summed. Here, we use sine and cosine\n",
        "        functions of different frequencies.\n",
        "    .. math::\n",
        "        \\text{PosEncoder}(pos, 2i) = sin(pos/10000^(2i/d_model))\n",
        "        \\text{PosEncoder}(pos, 2i+1) = cos(pos/10000^(2i/d_model))\n",
        "        \\text{where pos is the word position and i is the embed idx)\n",
        "    Args:\n",
        "        d_model: the embed dim (required).\n",
        "        dropout: the dropout value (default=0.1).\n",
        "        max_len: the max. length of the incoming sequence (default=1024).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=1024, scale_factor=1.0):\n",
        "        super(FixedPositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)  # positional encoding\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = scale_factor * pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)  # this stores the variable in the state_dict (used for non-trainable variables)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Inputs of forward function\n",
        "        Args:\n",
        "            x: the sequence fed to the positional encoder model (required).\n",
        "        Shape:\n",
        "            x: [sequence length, batch size, embed dim]\n",
        "            output: [sequence length, batch size, embed dim]\n",
        "        \"\"\"\n",
        "\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "yJ9wo_aR4rpG"
      },
      "outputs": [],
      "source": [
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, num_heads, hidden_dim, num_layers, dropout=0.1,max_len=1024):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.input_projection = nn.Linear(input_dim, hidden_dim)\n",
        "        self.positional_encoding = FixedPositionalEncoding(hidden_dim, dropout=dropout, max_len=max_len)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=hidden_dim,\n",
        "            nhead=num_heads,\n",
        "            activation=\"relu\",\n",
        "            dim_feedforward=hidden_dim * 4,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Input projection\n",
        "        x = self.input_projection(x)\n",
        "        x = self.positional_encoding(x)\n",
        "        # Pass through the transformer encoder\n",
        "        x = self.encoder(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "--aT1ndPLHxM"
      },
      "outputs": [],
      "source": [
        "class TransformerClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, num_heads, hidden_dim, num_layers, num_classes, dropout=0.1,max_len=1024):\n",
        "        super(TransformerClassifier, self).__init__()\n",
        "\n",
        "        # Transformer encoder\n",
        "        self.encoder = TransformerEncoder(\n",
        "            input_dim=input_dim,\n",
        "            num_heads=num_heads,\n",
        "            hidden_dim=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            dropout=dropout,\n",
        "            max_len=max_len\n",
        "        )\n",
        "\n",
        "        # Task-specific heads\n",
        "        self.stroke_head = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim//2),  # First layer\n",
        "            nn.ReLU(),                 # Activation function\n",
        "            nn.Linear(hidden_dim//2, 1)           # Output layer\n",
        "        )\n",
        "\n",
        "        # Player classification head (binary)\n",
        "        self.player_head = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim//2),  # First layer\n",
        "            nn.ReLU(),                 # Activation function\n",
        "            nn.Linear(hidden_dim//2, 2)           # Output layer\n",
        "        )\n",
        "\n",
        "        # Type classification head (binary)\n",
        "        self.type_head = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim//2),  # First layer\n",
        "            nn.ReLU(),                 # Activation function\n",
        "            nn.Linear(hidden_dim//2, 2)           # Output layer\n",
        "        )\n",
        "\n",
        "        # Role classification head (3-class)\n",
        "        self.role_head = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim//2),  # First layer\n",
        "            nn.ReLU(),                 # Activation function\n",
        "            nn.Linear(hidden_dim//2, 3)           # Output layer\n",
        "        )\n",
        "\n",
        "        # Impact classification head (4-class)\n",
        "        self.impact_head = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim//2),  # First layer\n",
        "            nn.ReLU(),                 # Activation function\n",
        "            nn.Linear(hidden_dim//2, 4)           # Output layer\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Extract features using the transformer encoder\n",
        "        features = self.encoder(x)\n",
        "\n",
        "        # Task-specific predictions\n",
        "        stroke_pred = self.stroke_head(features)\n",
        "        player_pred = self.player_head(features)\n",
        "        type_pred = self.type_head(features)\n",
        "        role_pred = self.role_head(features)\n",
        "        impact_pred = self.impact_head(features)\n",
        "\n",
        "        return stroke_pred, player_pred, type_pred, role_pred, impact_pred\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "cwyEYoYyC4ai"
      },
      "outputs": [],
      "source": [
        "def compute_multiclass_metrics(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Compute metrics for multiclass classification.\n",
        "\n",
        "    Args:\n",
        "        y_true: Ground truth labels (class indices as a numpy array or tensor).\n",
        "        y_pred: Predicted labels (class indices as a list, numpy array, or tensor).\n",
        "\n",
        "    Returns:\n",
        "        precision, recall, f1, accuracy: Computed metrics.\n",
        "    \"\"\"\n",
        "    if(len(y_pred)==0):\n",
        "      return (0,0,0,0)\n",
        "    # Convert y_pred to a NumPy array if it's a list\n",
        "    if isinstance(y_pred, list):\n",
        "        y_pred = np.concatenate(y_pred, axis=0)\n",
        "\n",
        "    # Convert y_true to a NumPy array if it's not already\n",
        "    if isinstance(y_true, list):\n",
        "        y_true = np.concatenate(y_true, axis=0)\n",
        "\n",
        "    # Ensure inputs are NumPy arrays for compatibility with scikit-learn metrics\n",
        "    if isinstance(y_true, torch.Tensor):\n",
        "        y_true = y_true.numpy()\n",
        "    if isinstance(y_pred, torch.Tensor):\n",
        "        y_pred = y_pred.numpy()\n",
        "\n",
        "    # Compute metrics\n",
        "    precision = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
        "    recall = recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "    return precision, recall, f1, accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "M5A0P9a3YRW0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "def aggregate_prediction_labels(label_predictions, true_labels, chunk_length, overlap):\n",
        "    \"\"\"\n",
        "    Aggregate predictions and true labels for overlapping chunks.\n",
        "\n",
        "    Args:\n",
        "        label_predictions (list of np.array): List of arrays containing predicted labels for each chunk.\n",
        "        true_labels (list of np.array): List of arrays containing true labels for each chunk.\n",
        "        chunk_length (int): Length of each chunk.\n",
        "        overlap (int): Overlap between consecutive chunks.\n",
        "\n",
        "    Returns:\n",
        "        aggregated_predictions (np.array): Aggregated predictions for the entire sequence.\n",
        "        aggregated_labels (np.array): Aggregated true labels for the entire sequence.\n",
        "    \"\"\"\n",
        "    assert len(label_predictions) == len(true_labels), \"Predictions and labels must have the same number of chunks.\"\n",
        "\n",
        "    # Step size and total sequence length\n",
        "    step = chunk_length - overlap\n",
        "    sequence_length = (len(label_predictions) - 1) * step + chunk_length\n",
        "\n",
        "    # Initialize arrays for aggregated predictions and labels\n",
        "    aggregated_predictions = [[] for _ in range(sequence_length)]\n",
        "    aggregated_labels = np.zeros((sequence_length))\n",
        "    # Populate aggregated labels\n",
        "    for i in range(sequence_length):\n",
        "        chunk_idx = i // step\n",
        "        offset = i % step\n",
        "        if chunk_idx >= len(true_labels):\n",
        "            chunk_idx = len(true_labels) - 1\n",
        "            offset = i % chunk_length\n",
        "        aggregated_labels[i] = true_labels[chunk_idx][offset]\n",
        "\n",
        "    # Populate aggregated predictions\n",
        "    for i, chunk in enumerate(label_predictions):\n",
        "        for j, pred in enumerate(chunk):\n",
        "            index = j + i * step\n",
        "            if index < sequence_length:\n",
        "                aggregated_predictions[index].append(pred.item() if isinstance(pred, np.ndarray) else pred)\n",
        "\n",
        "\n",
        "    # Majority voting for predictions\n",
        "    aggregated_predictions = np.array([\n",
        "        Counter(map(int, pred_list)).most_common(1)[0][0] if pred_list else -1\n",
        "        for pred_list in aggregated_predictions\n",
        "    ])\n",
        "\n",
        "    return aggregated_predictions, aggregated_labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZi2K8_bYmyH",
        "outputId": "df2bc82b-52ec-4089-a1ba-883d1e275405"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import wandb\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "# Initialize wandb\n",
        "#wandb.login(key=\"83c00bb6bf15c1285e4617518f9a3c0b65a13872\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "g2fkqEXPLSGr"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train_model(\n",
        "    model,\n",
        "    params,\n",
        "    train_dataloader,\n",
        "    val_dataloader,\n",
        "    optimizer,\n",
        "    loss_fn,\n",
        "    num_epochs,\n",
        "    device,\n",
        "    alpha=(1.0, 1.0, 1.0, 1.0, 1.0),  # Task weights\n",
        "    scheduler=None,\n",
        "    chunk_length=128,\n",
        "    overlap=8,\n",
        "    project_name=\"PRIM\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Train and validate the model, logging to wandb.\n",
        "    \"\"\"\n",
        "    # Initialize wandb project\n",
        "    #wandb.init(project=project_name)\n",
        "\n",
        "    # Log model architecture\n",
        "    #wandb.watch(model, log=\"all\")\n",
        "\n",
        "    model = model.to(device)\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        print(f\"\\nEpoch {epoch}/{num_epochs}\")\n",
        "        print(\"-\" * 20)\n",
        "\n",
        "        # Training Phase\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_steps = 0\n",
        "\n",
        "        metrics = {task: {\"precision\": 0, \"recall\": 0, \"f1\": 0, \"accuracy\": 0} for task in [\"stroke\",\"player\",\"type\",\"role\",\"impact\"]}\n",
        "\n",
        "        for batch in tqdm(train_dataloader, desc=\"Training\"):\n",
        "            x, y_true = batch\n",
        "            x = x.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            y_pred = model(x)\n",
        "            y_true = y_true.to(device)\n",
        "            # Compute loss\n",
        "            batch_loss = loss_fn(y_pred, y_true, alpha)\n",
        "\n",
        "            # Backward pass\n",
        "            optimizer.zero_grad()\n",
        "            batch_loss.backward()\n",
        "            max_norm = 1.0  # Set the maximum gradient norm\n",
        "            torch.nn.utils.clip_grad_norm_(params, max_norm)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += batch_loss.item()\n",
        "            train_steps += 1\n",
        "\n",
        "\n",
        "            y_pred_stroke, y_pred_player, y_pred_type, y_pred_role, y_pred_impact = y_pred\n",
        "\n",
        "            y_pred_stroke = (torch.sigmoid(y_pred_stroke).detach().cpu().numpy() > 0.5).astype(int)\n",
        "            y_pred_player = torch.argmax(torch.softmax(y_pred_player, dim=-1), dim=-1).detach().cpu().numpy()\n",
        "            y_pred_type = torch.argmax(torch.softmax(y_pred_type, dim=-1), dim=-1).detach().cpu().numpy()\n",
        "            y_pred_role = torch.argmax(torch.softmax(y_pred_role, dim=-1), dim=-1).detach().cpu().numpy()\n",
        "            y_pred_impact = torch.argmax(torch.softmax(y_pred_impact, dim=-1), dim=-1).detach().cpu().numpy()\n",
        "\n",
        "            y_true_stroke = y_true[:, :, 0].unsqueeze(-1).detach().cpu().numpy()\n",
        "            y_true_player = torch.argmax(y_true[:, :, 1:3], dim=-1).detach().cpu().numpy()\n",
        "            y_true_type = torch.argmax(y_true[:, :, 3:5], dim=-1).detach().cpu().numpy()\n",
        "            y_true_role = torch.argmax(torch.stack([y_true[:, :, 5], y_true[:, :, 6], y_true[:, :, 5] + y_true[:, :, 6]], dim=-1),\n",
        "              dim=-1,\n",
        "              ).detach().cpu().numpy()\n",
        "            y_true_impact = torch.argmax( torch.cat([y_true[:, :, 7:], torch.sum(y_true[:, :, 7:], dim=-1, keepdim=True)], dim=-1),\n",
        "                      dim=-1,\n",
        "              ).detach().cpu().numpy()\n",
        "\n",
        "            final_predictions = {\n",
        "                \"stroke\": y_pred_stroke,\n",
        "                \"player\": y_pred_player,\n",
        "                \"type\": y_pred_type,\n",
        "                \"role\": y_pred_role,\n",
        "                \"impact\": y_pred_impact\n",
        "            }\n",
        "            final_labels = {\n",
        "                \"stroke\": y_true_stroke,\n",
        "                \"player\": y_true_player,\n",
        "                \"type\": y_true_type,\n",
        "                \"role\": y_true_role,\n",
        "                \"impact\": y_true_impact\n",
        "            }\n",
        "            # Compute metrics on aggregated predictions\n",
        "\n",
        "\n",
        "            for task in metrics.keys():\n",
        "                if task != \"stroke\":  # Filter based on stroke predictions\n",
        "                    stroke_mask = (final_labels[\"stroke\"]==1).squeeze()\n",
        "                    task_y_true = final_labels[task][stroke_mask]\n",
        "                    task_y_pred = final_predictions[task][stroke_mask]\n",
        "                    if len(task_y_true) > 0:\n",
        "                        task_metrics = compute_multiclass_metrics(task_y_true, task_y_pred)\n",
        "                        metrics[task][\"precision\"] += task_metrics[0]\n",
        "                        metrics[task][\"recall\"] += task_metrics[1]\n",
        "                        metrics[task][\"f1\"] += task_metrics[2]\n",
        "                        metrics[task][\"accuracy\"] += task_metrics[3]\n",
        "                else:\n",
        "                    mask = (final_labels[\"stroke\"] != -1)\n",
        "                    task_y_true = final_labels[task][mask]\n",
        "                    task_y_pred = final_predictions[task][mask]\n",
        "                    task_metrics = compute_multiclass_metrics(\n",
        "                        task_y_true,\n",
        "                        task_y_pred\n",
        "                    )\n",
        "                    metrics[task][\"precision\"] += task_metrics[0]\n",
        "                    metrics[task][\"recall\"] += task_metrics[1]\n",
        "                    metrics[task][\"f1\"] += task_metrics[2]\n",
        "                    metrics[task][\"accuracy\"] += task_metrics[3]\n",
        "\n",
        "\n",
        "        for task in metrics.keys():\n",
        "          for metric in metrics[task] :\n",
        "            metrics[task][metric] /= train_steps\n",
        "\n",
        "        for task, task_metrics in metrics.items():\n",
        "          print(f\"{task.capitalize()} Metrics - Precision: {task_metrics['precision']:.4f}, Recall: {task_metrics['recall']:.4f}, F1: {task_metrics['f1']:.4f}, Accuracy: {task_metrics['accuracy']:.4f}\")\n",
        "\n",
        "        avg_train_loss = train_loss / train_steps\n",
        "        print(f\"Train Loss: {avg_train_loss:.4f}\")\n",
        "        print(f\"log vars:{log_vars}\")\n",
        "        \"\"\"\n",
        "        wandb.log({\n",
        "            \"epoch\": epoch,\n",
        "            \"train_loss\": avg_train_loss,\n",
        "            **{f\"{task}_{metric}\": value for task, task_metrics in metrics.items() for metric, value in task_metrics.items()}\n",
        "        })\n",
        "        \"\"\"\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        # Validation Phase\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_steps = 0\n",
        "\n",
        "        # Initialize containers for chunk predictions and labels\n",
        "        chunk_predictions = {task: [] for task in [\"stroke\", \"player\", \"type\", \"role\", \"impact\"]}\n",
        "        chunk_labels = {task: [] for task in [\"stroke\", \"player\", \"type\", \"role\", \"impact\"]}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(val_dataloader, desc=\"Validation\"):\n",
        "                x, y_true = batch\n",
        "                x = x.to(device)\n",
        "                y_true = y_true.to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                y_pred = model(x)\n",
        "\n",
        "                # Compute loss\n",
        "                batch_loss = loss_fn(y_pred, y_true, alpha=alpha)\n",
        "                val_loss += batch_loss.item()\n",
        "                val_steps += 1\n",
        "\n",
        "                # Extract predictions for each task\n",
        "                y_pred_stroke, y_pred_player, y_pred_type, y_pred_role, y_pred_impact = y_pred\n",
        "                chunk_predictions[\"stroke\"].append((torch.sigmoid(y_pred_stroke).cpu().numpy() > 0.5).astype(int))\n",
        "                chunk_predictions[\"player\"].append(torch.argmax(torch.softmax(y_pred_player, dim=-1), dim=-1).cpu().numpy())\n",
        "                chunk_predictions[\"type\"].append(torch.argmax(torch.softmax(y_pred_type, dim=-1), dim=-1).cpu().numpy())\n",
        "                chunk_predictions[\"role\"].append(torch.argmax(torch.softmax(y_pred_role, dim=-1), dim=-1).cpu().numpy())\n",
        "                chunk_predictions[\"impact\"].append(torch.argmax(torch.softmax(y_pred_impact, dim=-1), dim=-1).cpu().numpy())\n",
        "\n",
        "\n",
        "                # Extract true labels for each task\n",
        "                # True labels for stroke are binary, no need to change\n",
        "                y_true_stroke = y_true[:, :, 0].unsqueeze(-1).cpu().numpy()\n",
        "\n",
        "                # Convert one-hot encoded labels to class indices\n",
        "                y_true_player = torch.argmax(y_true[:, :, 1:3], dim=-1).cpu().numpy()\n",
        "                y_true_type = torch.argmax(y_true[:, :, 3:5], dim=-1).cpu().numpy()\n",
        "                y_true_role = torch.argmax(\n",
        "                    torch.stack([y_true[:, :, 5], y_true[:, :, 6], y_true[:, :, 5] + y_true[:, :, 6]], dim=-1),\n",
        "                    dim=-1,\n",
        "                ).cpu().numpy()\n",
        "                y_true_impact = torch.argmax(\n",
        "                    torch.cat([y_true[:, :, 7:], torch.sum(y_true[:, :, 7:], dim=-1, keepdim=True)], dim=-1),\n",
        "                    dim=-1,\n",
        "                ).cpu().numpy()\n",
        "\n",
        "                # Append converted labels to chunk-level containers\n",
        "                chunk_labels[\"stroke\"].append(y_true_stroke)\n",
        "                chunk_labels[\"player\"].append(y_true_player)\n",
        "                chunk_labels[\"type\"].append(y_true_type)\n",
        "                chunk_labels[\"role\"].append(y_true_role)\n",
        "                chunk_labels[\"impact\"].append(y_true_impact)\n",
        "\n",
        "\n",
        "\n",
        "        # Aggregate predictions and labels\n",
        "        final_predictions = {}\n",
        "        final_labels = {}\n",
        "        for task in chunk_predictions.keys():\n",
        "            chunk_predictions[task] = np.concatenate(chunk_predictions[task], axis=0)\n",
        "            chunk_labels[task] = np.concatenate(chunk_labels[task], axis=0)\n",
        "\n",
        "            final_predictions[task], final_labels[task] = aggregate_prediction_labels(\n",
        "                chunk_predictions[task], chunk_labels[task], chunk_length, overlap\n",
        "            )\n",
        "        # Compute metrics on aggregated predictions\n",
        "        metrics = {task: {\"precision\": 0, \"recall\": 0, \"f1\": 0, \"accuracy\": 0} for task in final_predictions.keys()}\n",
        "        for task in metrics.keys():\n",
        "            if task != \"stroke\":  # Filter based on stroke predictions\n",
        "                stroke_mask = (final_labels[\"stroke\"]==1)\n",
        "                task_y_true = final_labels[task][stroke_mask]\n",
        "                task_y_pred = final_predictions[task][stroke_mask]\n",
        "                if len(task_y_true) > 0:\n",
        "                    task_metrics = compute_multiclass_metrics(task_y_true, task_y_pred)\n",
        "                    metrics[task][\"precision\"] += task_metrics[0]\n",
        "                    metrics[task][\"recall\"] += task_metrics[1]\n",
        "                    metrics[task][\"f1\"] += task_metrics[2]\n",
        "                    metrics[task][\"accuracy\"] += task_metrics[3]\n",
        "            else:\n",
        "                mask = (final_labels[\"stroke\"] != -1)\n",
        "                task_y_true = final_labels[task][mask]\n",
        "                task_y_pred = final_predictions[task][mask]\n",
        "                task_metrics = compute_multiclass_metrics(\n",
        "                    task_y_true,\n",
        "                    task_y_pred\n",
        "                )\n",
        "                metrics[task][\"precision\"] += task_metrics[0]\n",
        "                metrics[task][\"recall\"] += task_metrics[1]\n",
        "                metrics[task][\"f1\"] += task_metrics[2]\n",
        "                metrics[task][\"accuracy\"] += task_metrics[3]\n",
        "\n",
        "        avg_val_loss = val_loss / val_steps\n",
        "        print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
        "        for task, task_metrics in metrics.items():\n",
        "            print(f\"{task.capitalize()} Metrics - Precision: {task_metrics['precision']:.4f}, Recall: {task_metrics['recall']:.4f}, F1: {task_metrics['f1']:.4f}, Accuracy: {task_metrics['accuracy']:.4f}\")\n",
        "\n",
        "        # Log metrics to wandb\n",
        "        wandb.log({\n",
        "            \"epoch\": epoch,\n",
        "            \"train_loss\": avg_train_loss,\n",
        "            \"val_loss\": avg_val_loss,\n",
        "            **{f\"{task}_{metric}\": value for task, task_metrics in metrics.items() for metric, value in task_metrics.items()}\n",
        "        })\n",
        "\n",
        "        # Learning rate scheduler step (optional)\n",
        "        if scheduler:\n",
        "            scheduler.step(avg_val_loss)\n",
        "\n",
        "        # Save the best model\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            torch.save(model.state_dict(), \"best_model.pth\")\n",
        "            print(\"Best model saved.\")\n",
        "\n",
        "    print(\"\\nTraining Complete\")\n",
        "    print(f\"Best Validation Loss: {best_val_loss:.4f}\")\n",
        "    \"\"\"\n",
        "    #wandb.finish()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5_PXZSFr5YLn",
        "outputId": "d5951725-ce25-4dc1-fde0-f140062885f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Log Vars: Parameter containing:\n",
            "tensor([0., 0., 0., 0., 0.], requires_grad=True)\n",
            "\n",
            "Epoch 1/10000\n",
            "--------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 13/13 [00:08<00:00,  1.45it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stroke Metrics - Precision: 0.4727, Recall: 0.4872, F1: 0.4799, Accuracy: 0.9703\n",
            "Player Metrics - Precision: 0.2419, Recall: 0.5000, F1: 0.3258, Accuracy: 0.4837\n",
            "Type Metrics - Precision: 0.2698, Recall: 0.5000, F1: 0.3451, Accuracy: 0.5395\n",
            "Role Metrics - Precision: 0.4456, Recall: 0.5000, F1: 0.4710, Accuracy: 0.8911\n",
            "Impact Metrics - Precision: 0.3586, Recall: 0.4359, F1: 0.3932, Accuracy: 0.8213\n",
            "Train Loss: nan\n",
            "log vars:Parameter containing:\n",
            "tensor([nan, nan, nan, nan, nan], requires_grad=True)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "ename": "Error",
          "evalue": "You must call wandb.init() before wandb.log()",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mError\u001b[0m                                     Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[25], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Train and validate\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Task weights\u001b[39;49;00m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverlap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverlap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunk_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunk_length\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[23], line 133\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, params, train_dataloader, val_dataloader, optimizer, loss_fn, num_epochs, device, alpha, scheduler, chunk_length, overlap, project_name)\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_train_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog vars:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlog_vars\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 133\u001b[0m     \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain_loss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mavg_train_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtask\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmetric\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtask_metrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \n\u001b[0;32m    142\u001b[0m \u001b[38;5;124;03m    # Validation Phase\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;124;03mprint(f\"Best Validation Loss: {best_val_loss:.4f}\")\u001b[39;00m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\ASUS\\Desktop\\PRIM\\prim\\lib\\site-packages\\wandb\\sdk\\lib\\preinit.py:36\u001b[0m, in \u001b[0;36mPreInitCallable.<locals>.preinit_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreinit_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m---> 36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m wandb\u001b[38;5;241m.\u001b[39mError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must call wandb.init() before \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[1;31mError\u001b[0m: You must call wandb.init() before wandb.log()"
          ]
        }
      ],
      "source": [
        "# Example setup\n",
        "model = TransformerClassifier(\n",
        "    input_dim=116,\n",
        "    num_heads=4,\n",
        "    hidden_dim=192,\n",
        "    num_layers=4,\n",
        "    num_classes=None,\n",
        "    dropout=0.1,\n",
        "    max_len=128\n",
        ")\n",
        "\n",
        "log_vars = nn.Parameter(torch.zeros(5))  # Create the parameter\n",
        "print(\"Log Vars:\", log_vars)\n",
        "\n",
        "# Combine model parameters and log_vars in the optimizer\n",
        "params = list(model.parameters()) + [log_vars]  # Directly add log_vars\n",
        "#params = list(model.parameters())\n",
        "optimizer = torch.optim.Adam(params, lr=1e-4)  # Use params for optimization\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5)\n",
        "loss_fn = loss\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Train and validate\n",
        "train_model(\n",
        "    model=model,\n",
        "    params=params,\n",
        "    train_dataloader=train_dataloader,\n",
        "    val_dataloader=None,\n",
        "    optimizer=optimizer,\n",
        "    loss_fn=loss_fn,\n",
        "    num_epochs=10000,\n",
        "    device=device,\n",
        "    alpha=log_vars,  # Task weights\n",
        "    scheduler=scheduler,\n",
        "    overlap=overlap,\n",
        "    chunk_length=chunk_length\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "391ZD_ixNDyN"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/PRIM/models/converge.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7Tg3nMduZG8"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Still have small issue with ignoring the padding in the model\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eU04krzWdtv1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "prim",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
